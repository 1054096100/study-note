# 《现代操作系统》

## 1、引论

多数计算机有两种运行模式：内核态和用户态。在内核态，程序具有对所有硬件的完全访问权，可以执行机器能够运行的任何指令。软件的其余部分运行在用户态下。在用户态下，只使用了机器指令中的一个子集。特别地，那些会影响机器的控制或可进行I/O操作的指令，在用户态中的程序里是禁止的。

在磁盘的情况下，典型的抽象是包含了一组**已命名文件的一个磁盘**。每个文件可以打开进行读写操作，然后进行读写，最后关闭文件。

### 作为资源管理者的操作系统

操作系统的主要任务是记录哪个程序在使用什么资源，对资源请求进行分配，评估使用代价，并且为不同的程序和用户调解互相冲突的资源请求。

资源管理包括用以下两种不同的方式实现多路复用（共享）资源：在时间上复用和在空间上复用。

#### 时间复用

针对时间复用的例子是多个进程之间进行切换。

操作系统必须知晓所有的寄存器。在时间多路复用CPU中，操作系统经常会中止正在运行的某个程序并启动（或再启动）另一个程序。每次停止yield运行着的程序时，操作系统必须保存所有的寄存器，这样在稍后该程序被再次运行时，可以把这些寄存器重新装入。

#### 空间复用

针对空间复用的例子是每个客户都得到资源的一部分，从而取代了客户排队。例如，通常在若干运行程序之间分隔内存，这样每一个运行程序都可以同时入住内存（例如，为了轮流使用CPU）。**假设有足够的内存可以存放多个程序，那么在内存中同时存放若干个程序的效率，比把所有内存都分给一个程序的效率要高得多**。特别是一个程序只需要整个内存的一小部分时，结果更是这样。当然，如此的做法会引起公平，保护等问题，这有赖于操作系统解决它们。

### 多道程序设计

对于CPU操作密集的科学计算问题（密集计算指的是密集的使用CPU），I/O操作较少，因此浪费的时间很少。然而，对于商业数据处理，I/O操作等待的时间通常占到80%~90%，所以必须采取某种措施减少（昂贵的）CPU空闲时间的浪费。

解决方案是将内存分几个部分，每一部分存放不同的作业，如图：

![](http://oklbfi1yj.bkt.clouddn.com/%E3%80%8A%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E3%80%8B/1.png)

当一个作用等待I/O操作完成时，另一个足以可以使用CUP。如果内存中可以同时存放足够多的作业，则CPU利用率可以接近100%。

### 计算机硬件介绍

#### 处理器

计算机的“大脑”是CPU，它**从内存中取出指令**并执行之。由于用来访问内存以得到指令或数据的时间要比执行指令花费的时间长得多，因此，所有的CPU内都有一些用来保存关键变量和临时数据的寄存器。

一般而言，在用户态中有关I/O和内存保护的所有指令都是禁止的。**为了从操作系统中获得服务，用户程序必须使用系统调用**。**系统调用陷入内核并调用操作系统**。TRAP指令把用户态换成内核态，并启用操作系统。

计算机使用陷阱而不是一条指令来执行系统调用。其他的多数陷阱是由硬件引起的，用于警告有**异常情况发生**，诸如试图被零除或浮点下溢等。在所有的情况下，**操作系统都得到控制权并决定如何处理异常情况**。

多核芯片上有效的安装了多个芯片，每个小芯片都是一个独立的CPU。

![](http://oklbfi1yj.bkt.clouddn.com/%E3%80%8A%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E3%80%8B/2.PNG)

#### 存储器

存储器系统的底层是CPU中的寄存器。它们用与CPU相同的材料制成，所以和CPU一样快。显然，访问它们是没有时延的。

许多计算机已经在使用少量的非易失性随机访问存储器。它们与RAM不同，在电源切断之后，非易失性随机访问存储器并不丢失其内容。只读存储器（ROM）在工厂中就被编程完毕，然后再也不能被修改。ROM速度快且便宜。在有些计算机中，**用于启动计算机的引导加载模块就存放在ROM中**。

#### 磁盘

磁盘低速的原因是因为**磁盘是一种机械装置**。

许多计算机支持一种著名的虚拟内存机制。这种机制使得期望运行大于物理内存（主存）的程序成为可能，其方法是将程序放在磁盘上，而将主存作为一种缓存，用来保存最频繁使用的部分程序。**这种机制需要快速地映像内存地址，以便把程序生成的地址转换为有关字节在RAM中的物理地址**。这种映像由CPU中的一个部件，称为存储器管理单元来完成。

### 操作系统概念

#### 进程

进程本质上是正在执行的一个程序。**与每个进程相关的是进程的地址空间**，这是从某个最小值的存储位置（通常是0）到某个最大值存储位置的列表。在这个地址空间中，进程可以进行读写。该地址空间中存放有可执行程序、程序的数据以及程序的堆栈。与每个进程相关的还有资源集，通常包括寄存器（含有程序计数器和堆栈指针）、打开的文件的清单，以及运行该程序所需要的所有其他信息等等。**进程基本上是容纳运行一个程序所需要所有信息的容器**。

一个进程暂时被挂起后，在随后的某个时刻里，该进程再次启动时的状态必须与先前暂停时完全相同，这就意味着在挂起时该进程的所有信息都要保存下来。例如，为了同时读入信息，进程打开了若干文件。同每个被打开文件有关的是指向当前位置的指针（即下一个将读出的字节或记录）。在一个进程暂时被挂起时，所有这些指针都必须保存起来，这样在该进程重新启动之后，所执行的读调用才能读到正确的数据。**在许多操作系统中，与一个进程有关的所有信息，除了该进程自身地址空间的内容以外，均存放在操作系统的一张表中，称为进程表。进程表是数组（或链表）结构，当前存在的每个进程都要占用其中一项**。

所以，一个挂起的进程包括：进程的地址空间，以及对应的进程表项，其中包括寄存器以及稍后重启该进程所需的许多其他信息。

与进程管理最有关的最关键的系统调用是那些进程创建和进程终止的系统调用。考虑一个典型的例子。有一个称为命令解释器或shell的进程从终端上读命令。此时，用户刚键入一条命令要求编译一个程序。shell必须先创建一个新进程来执行编译程序。当执行编译的进程结束时，它执行一条系统调用来终止自己。

#### 地址空间

每台计算机都有一些主存，用来保存正在执行的程序。**在非常简单的操作系统中，内存中一次只能有一个程序。如果要运行第二个程序，第一个程序就必须被移出内存，再把第二个程序装入内存**。

较复杂的操作系统允许在内存中同时运行多道程序。为了避免它们彼此互相干扰（包括操作系统），需要有某种保护机制。

上述观点涉及对计算机主存的管理和保护。另一种不同的但是同样重要并与存储器有关的内容，是管理进程的地址空间。通常，每个进程有一些可以使用的地址集合，典型值从0开始直到某个最大值。在最简单的情形下，一个进程可拥有的最大地址空间小于主存。在这种方式下，进程可以用满其地址空间，而且内存中也有足够的空间容纳该进程。

但是，在许多32位或64位地址的计算机中，分别有2的32次方或2的64次方字节的地址空间。如果一个进程有比计算机拥有的主存还大的地址空间，而且该进程希望使用全部的内存，在早期的计算机中，这个进程只好承认坏运气了。现在，有了一种称为虚拟内存的技术，操作系统可以把部分地址空间装入主存，部分留在磁盘上，并且在需要时穿梭交换它们。

#### 文件

管道是一个**既与进程有关也与文件有关**的特性。管道是一种虚文件，它可连接两个进程，如图：

![](http://oklbfi1yj.bkt.clouddn.com/%E3%80%8A%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E3%80%8B/3.PNG)

如果进程A和B希望通过管道对话，它们必须提前设置该管道。**当进程A想对进程B发送数据时，它把数据写到管道上，仿佛管道就是输出文件一样。进程B可以通过读该管道而得到数据，仿佛该管道就是一个输入文件一样**。这样，在UNIX中两个进程之间的通信就很类似于普通文件的读写了。更为强大的是，若进程想要发现它所写入的输出文件不是真正的文件而是管道，则需要使用特殊的系统调用。

#### shell

这是一个**命令解释器**。shell是终端用户与操作系统之间的界面。有许多中类的shell，如sh、csh、ksh以及bash等。

### 系统调用

#### 系统调用和过程调用的区别

系统调用可以进入内核，而过程调用则不能。

### 操作系统结构

#### 客户机-服务器模式

一个微内核思想的略微变体是将进程划分为两类：**服务器，每个服务器提供某种服务；客户端，使用这些服务**。这个模式就是所谓的客户机-服务器模式。通常，在系统最底层是微内核，但并不是必须这样的。**这个模式的本质是存在客户端进程和服务器进程**。

![](http://oklbfi1yj.bkt.clouddn.com/%E3%80%8A%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E3%80%8B/4.PNG)



### 依靠C的世界

#### 大型编程项目

由于操作系统非常大（500万行代码是很寻常的），当编写操作系统的时候，每当操作系统文件修改后就完全重新编译是不能忍受的。另一方面，改变了用在成千个文件中的一个关键头文件，确实需要新编译这些文件。没有一定的协助，要想记住哪个目标文件与哪个头文件相关是完全不可行的。

幸运的是，计算机非常善于处理事务分类。在UNIX系统中，有个名为make的程序，它读入Makefile，该**Makefile说明哪个文件与哪个文件相关**。make的作用是，在构建操作系统二进制码时，检测此刻需要哪个目标文件，而且对于每个文件，检查自动上次目标文件创建之后，是否有任何它依赖（代码和头文件）的文件已经被修改了。如果有，目标文件需要重新编译。在make确定了哪个`.o`文件需要重新编译之后，它调用C编译器重新编译这些文件，这样，就把编译的次数减到了最低限度。

## 2、进程与线程

### 原子操作

是指一组相关联的操作**要么都不间断地执行**，**要么都不执行**。

原子性**不可能由软件单独保证--必须需要硬件的支持**，因此是和架构相关的。**在x86 平台上，CPU提供了在指令执行期间对总线加锁**的手段。

### 进程

#### 进程模型

![](http://oklbfi1yj.bkt.clouddn.com/%E3%80%8A%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E3%80%8B/5.PNG)

在一台多道程序计算机的内存中有4道程序。在图2-1中，这4道程序被抽象为4个各自拥有自己控制流程（即每个程序自己的逻辑程序计算器）的进程，并且每个程序都独立地运行。当然，**实际上只有一个物理程序计数器，所以在每个程序运行时，它的逻辑程序计数器被装入实际的程序计数器中。当该程序执行结束（或暂停执行）时，物理程序计数器被保存在内存中该进程的逻辑程序计数器中**。在图2-1c中我们看到，在观察足够长的一段时间后，所有的进程都运行了，但在任何一个给定的瞬间仅有一个进程真正在运行。

#### 创建进程

在所要从事的工作可以容易地划分**若干相关的但没有相互作用**的的进程时，创建新的进程就特别有效果。例如，如果有大量的数据要通过网络调取并进行顺序处理，那么创建一个进程取数据，并把数据放入共享缓冲区中，而让第二个进程取走数据项并处理之，应该比较容易。

从技术上看，在所有情形中，**新进程都是由于一个已存在的进程执行了一个用于创建进程的系统调用而创建的**，**这个系统调用通知操作系统创建一个进程，并且直接或间接地指定该进程中运行的程序**。这个进程可以是一个运行的用户程序，一个由键盘或鼠标启动的系统进程或者一个批处理管理进程。

在UNIX系统中，只有一个系统调用可以用来创建新进程：fork。这个系统调用会创建一个与调用进程**相同的副本**。在调用了fork后，这两个进程（父进程和子进程）**拥有相同的存储映像**（但是**父进程和子进程有各自不同的地址空间**）、同样的环境字符串和**同样的打开文件**。通常，子进程接着执行execve或一个类似的系统调用，以修改其存储映像并运行一个新的程序。

因为父进程和子进程有各自不同的地址空间，所以，如果其中**某个进程在其自己的地址空间中修改了一个字，这个修改对其他进程而言是不可见的**。但是，不写写的内存区是共享的。（某些UNIX的实现使程序正文段在两者共享，因为它不能被修改）。但是，对于一个新创建的进程而言，**确实有可能共享其创建者的其他资源，诸如打开的文件等**。

#### 进程的层次结构

在UNIX中，进程和它的子女以及后裔共同组成一个进程组。

##### UNIX在启动时初始化自己

一个称为`init`的特殊进程出现在启动映像中。它为每个终端创建一个进程。这些进程等待用户登录。在整个系统中，所有进程都属于以`init`为根的一棵树。

#### 进程的状态

1、运行态（该时刻进程时间**占用CPU**）

2、就绪态（可运行，但**因为其他进程正在运行而暂时停止**）

3、阻塞态（除非某种释放它的外部事件发生，否则进程不能运行。所以**阻塞态不能直接到运行态**）

前两种状态在逻辑上是类似的。处于这两种状态的进程都可以运行，**只是对于就绪态暂时没有CPU分配给它**。第三种状态与前两种状态不同，**处于阻塞态的进程不能运行，即时CPU空闲也不行**，需要某种外部事件发生才行。

![](http://oklbfi1yj.bkt.clouddn.com/%E3%80%8A%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E3%80%8B/6.PNG)

在操作系统发现进程不能继续运行下去时，发生转换1。在某些系统中，**进程可以执行一个诸如`pause`的系统调用来进入阻塞状态**。在UNIX中，第一个进程从管道或设备文件（例如终端）读取数据时，**如果没有有效的输入存在，则进程会被自动阻塞**。

当进程等待的一个外部事件发生时（如一些输入到达），则发生转换4。如果此时没有其他进程运行，则立即触发转换3，该进程便开始运行。否则该进程将处于就绪态，等待CPU空闲并且轮到它运行。

#### 进程的实现

为了实现进程模型，操作系统维护着一张表格（一个结构数组），即进程表。每个进程占用一个进程表项（也叫做**进程控制块**）。该表项包含了进程状态的重要信息，包括**程序计数器、堆栈指针、内存分配状况、所有打开文件的状态**，以及其他在进程由运行态转换到就绪态或阻塞态时必须保存的信息，从而保证该进程随后能再次启动，就像从未被中断一样。

### 进程间通信

这里有三个问题。第一个问题与上面的叙述有关，即一个进程如何把信息传递给另一个。第二个要处理的问题是，确保两个或更多的进程在关键活动中不会出现交叉，例如，在飞机订票系统中的两个进程为不同的客户试图争夺飞机上的最后一个座位。第三个问题与正确的顺序有关（如果该顺序是有关联的话），比如，如果进程A产生数据而进程B打印数据，那么B在打印之前必须等待，直到A已经产生一些数据。

#### 临界区

如何避免竞态条件？实际上凡是涉及共享内存，共享文件以及共享任何资源的情况都会引发竞争。要避免竞争，关键是要找出某种途径来阻止多个进程同时读写共享的数据，即**互斥**，也就是说，当一个进程在使用一个共享变量或文件时，其他进程不能做出同样的操作。也就是**一个进程没有使用完这个共享变量或文件，其他进程就不能对它们做出操作**。

我们**把对共享内存进行访问的程序片段称作临界区域或临界区**。如果我们能够**适当地安排，使得两个进程不可能同时处于临界区中，就能够避免静态条件**。

#### 实现互斥的方案

##### 锁变量

设想有一个共享（锁）变量，其初始值为0。当一个进程想进入其临界区时，它首先测试这把锁。如果该锁的值为0，则该进程将其设置为1并进入临界区。若这把锁的值已经为1，则该进程将等待直到其值变为0。于是，0就表示临界区内没有进程，1表示已经有某个进程进入临界区。

但是，这种想法也包含了一个疏漏。假设一个进程读出锁变量的值并发现它为0，而恰好在它将其值设置为1之前，另一个进程被调度运行，将该锁变量设置为1。当第一个进程再次能运行时，它同样也将该锁设置为1，则此时同时有两个进程进入临界区中。

#### 睡眠与唤醒

##### 生存者-消费者问题

两个进程共享一个公共的固定大小的缓冲区。其中一个是生产者，将信息放入缓冲区；另一个是消费者，从缓冲区中取出信息。（我们这里只讨论一个生产者和一个消费者的情况）

问题在于当缓冲区已满，而此时生产者还想向其中放入一个新的数据项的情况。其解决办法是让生产者睡眠，待消费者从缓冲区中取出一个或多个数据项时再唤醒它。同样地，当消费者试图从缓冲区中取数据而发现缓冲区为空时，消费者就睡眠，直到生产者向其中放入一些数据时再将其唤醒。

为了跟踪缓冲区中的数据项数，我们需要一个变量count。如果缓冲区最多存放N个数据项，则生产者代码将首先检查count是否达到N，若是，则生产者睡眠；否则生产者向缓冲区中放入一个数据项并增加count的值。

消费者的代码与此类似：首先测试count是否为0，若是，则睡眠；否则从中取走一个数据项并递减count的值。每个进程同时也检测另一个进程是否应被唤醒，若是则唤醒之。

但是，这里也会出现一样的竞争条件。其原因是对count的访问未加限制。有可能出现一下情况：缓冲区为空，消费者刚刚读取count的值发现它为0。此时，调度程序刚好决定暂停消费者（此时消费者处于就绪态）并启动生产者。生产者向缓冲区中加入一个数据项，count加1。现在count的值变为了1。生产者推断认为由于count刚才为0，所以消费者此时一定在睡眠，于是生产者调用wakeup来唤醒消费者。但是，消费者此时在逻辑上并未睡眠，所以wakeup信号丢失。当消费者下次运行时，它将测试先前读到的count值，发现它为0，于是睡眠。生产者迟早会填满整个缓冲区，然后睡眠。这样一来，两个进程都将永远睡眠下去。

#### 信号量

信号量就是在一个叫做互斥区的门口放一个盒子，盒子里面装着固定数量的小球，每个线程过来的时候，都从盒子里面摸走一个小球，然后去互斥区里面浪（？），浪开心了出来的时候，再把小球放回盒子里。如果一个线程走过来一摸盒子，得，一个球都没了，不拿球不让进啊，那就只能站在门口等一个线程出来放回来一个球，再进去。这样由于小球的数量是固定的，那么互斥区里面的最大线程数量就是固定的，不会出现一下进去太多线程把互斥区给挤爆了的情况。这是用信号量做并发量限制。
另外一些情况下，小球是一次性的，线程拿走一个进了门，就把小球扔掉了，这样用着用着小球就没了，不过有另外一些线程（一般叫做生产者）会时不时过来往盒子里再放几个球，这样就可以有新的线程（一般叫做消费者）进去了，放一个球进一个线程，这是信号量做同步功能。你截图里的例子就是这个情况，主线程是生产者，通过sem_post往盒子里放小球（信号量加一），而其他线程是消费者，通过sem_wait从盒子里拿小球（信号量减一），如果遇到盒子里一个小球都没有（信号量为0），就会开始等待信号量不为0，然后拿走一个小球（信号量减一）再继续。
本质上来说信号量就是那个盒子，以及“摸不到球就不让进”这个机制。

（作者：灵剑链接：[https://www.zhihu.com/question/47411729/answer/105848845](https://www.zhihu.com/question/47411729/answer/105848845)来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。）

信号量是使用一个整型变量来累计唤醒次数，供以后使用。

信号量可以用来实现同步。

对信号量有两种操作：down和up。对信号量执行down操作，则是检查其值是否大于0.若该值大于0，则将其值减1（即用掉一个保存的唤醒信号）并继续；若该值为0，则进程将睡眠，而此时down操作并未结束。

其中，检查数值、修改变量值以及可能发生的睡眠均作为一个单一的、不可分割的原子操作完成。一旦一个信号量操作开始，则在该操作完成或阻塞之前，其他进程均不允许访问该信号量。

#### 互斥量

如果不需要信号量的计数能力，有时可以使用**信号量的一个简化版本，称为互斥量**（**mutex**）。互斥量仅仅适用于管理共享资源或一小段代码。

互斥量是一个可以处于两态之一的变量：**解锁和加锁**。

出互斥量之外，**pthread**提供了一种同步机制：条件变量。互斥量在允许或阻塞对临界区的访问上是很有用的，条件变量则允许线程由于一些未到达的条件而阻塞。绝大部分情况下，这两种方法是一起使用的。

#### 管程

管程是一种高级同步原语。

管程有一个很重要的特性，即**任一时刻管程中只能有一个活跃进程**，这一特性使管程能有效地完成互斥。

第一个进程调用管程过程时，该过程中的前几条指令将检查在管程中是否有其他的活跃进程。如果有，调用进程将被挂起，直到另一个进程离开管程将其唤醒。如果没有活跃进程在使用管程，则该调用进程可以进入。

进入管程时的**互斥由编译器负责**。所以出错的可能性小得多。

#### 消息传递

##### 消息传递系统的设计要点

消息传递系统面临着许多信号量和管程所未涉及的问题和设计难点，特别是位于网络中不同机器上的通信进程的情况。例如，消息有可能被网络丢失。为了防止消息丢失，发送方和接收方可以达成如下一致：一旦接收到信息，接收方马上回送一条特殊的确认信息。**如果发送方在一段时间间隔内未收到确认，则重发消息**。

### 线程

在传统操作系统中，每个进程有一个地址空间和一个控制线程。经常存在**在同一个地址空间中**准并行运行多个控制线程的情形，这些线程就像（差不多）分离的进程（共享地址空间除外）。

#### 线程的使用

##### 在一个进程中再有线程的原因

##### 原因一

主要原因是，在许多应用中同时发生着多种活动。其中，**某些活动随着时间的推移会被阻塞。通过将这些应用程序分解成可以准并行运行的多个顺序线程，程序设计模型会变得更简单**。

##### 原因二

线程比进程更轻量级，所以它们比进程更快创建，也更容易撤销。在许多系统中，创建一个线程比创建一个进程要快10~100倍。

##### 原因三

若多个线程都是CPU密集型的，那么并不能获得性能上的增强，但是**如果存在大量的计算和大量的I/O处理，拥有多个线程允许这些活动彼此重叠进行，从而会加快应用程序执行的速度**。

那些必须处理大量数据的应用。通常的处理方式是，读进一块数据，对其处理，然后再写出数据。这里的问题是，如果只能使用阻塞系统调用，那么在数据进入和数据输出时，会阻塞进程。在有大量计算需要处理的时候，让CPU空转显然是浪费，应该尽可能避免。

多线程提供了一种解决方案，有关的进程可以用一个输入线程、一个处理线程和一个输出线程构造。输入线程把数据读入到输入缓冲区（内核态）；处理线程从输入缓冲区中读取数据，处理数据（用户态），并把结果放到输出缓冲区中；输出线程把这些结果写到磁盘上（内核态）。按照这种工作方式，**输入、处理和输出可以全部同时进行**。当然，**这种模型只有当系统调用只阻塞调用线程而不是阻塞整个进程时，才能正常工作**。

### 典型的线程模型

理解进程的一个角度是，用某种方法把相关的资源集中在一起。进程有存放程序正文和数据以及其他资源的地址空间。进程至少拥有一个执行的线程。在线程中有一个程序计数器，用来记录接着要执行哪一条指令。线程拥有寄存器，用来保存线程当前的工作变量。线程还拥有一个堆栈，用来记录执行历史。尽管线程必须在某个进程中执行，但是线程和它的进程是不同的概念，并且可以分别处理。**进程用于把资源集中到一起，而线程则是在CPU上被调度执行的实体**。

线程给进程模型增加了一项内容，即在同一个进程环境中，允许彼此之间有较大独立性的多个线程执行。**在同一个进程中并行运行多个线程，是对在同一台计算机上并行运行多个进程的模拟**。

进程中的不同线程不像不同进程之间那样存在很大的独立性。所有的线程都有完全一样的地址空间，这意味着它们也共享同样的全局变量。由于各个线程都可以访问进程地址空间中的每一个内存地址，所以，一个线程可以读、写或甚至清楚另一个线程的堆栈。线程之间是没有保护的，原因是：1、不可能，2、没有必要。这与不同进程是由差别的。不同的进程会来自不同的用户，它们彼此之间可能有敌意，一个进程总是由某个用户所拥有，该用户创建多个线程应该是为了它们之间的合作而不是彼此间争斗。这样，**对于相互之间没有关系的线程而言，实际上用多进程会好一些**。

所以，线程概念试图实现的是，**共享一组资源的多个线程的执行能力，以便这些线程可以为完成某一任务而共同工作**。

**每个线程有其自己的堆栈**，

![](http://oklbfi1yj.bkt.clouddn.com/%E3%80%8A%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E3%80%8B/7.PNG)

在多线程的情况下，进程通常会从当前的单个线程开始。这个线程有能力通过调用一个库函数创建新的线程。有时，线程是有层次的，它们具有一种父子关系，但是，通常不存在这样一种关系，**所有的线程都是平等的**。

### 调度

进程切换的代价是比较高的。首先用户态必须切换到内核态；然后保存当前进程的状态，包括在进程表中存储寄存器值以便以后重新装载。接着，通过运行调度算法选定一个新进程；之后，将新进程的内存映像重新装入MMU；最后新进程开始运行。除此之外，进程切换还要是整个内存高速缓存失效，强迫缓存从内存中动态重新装入两次（进入内核一次，离开内核一次）。总之，如果每秒切换进程的次数太多，会**耗费大量CPU时间**，所以有必要提醒注意。

#### 进程行为

![](http://oklbfi1yj.bkt.clouddn.com/%E3%80%8A%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E3%80%8B/8.PNG)

某些进程花费了绝大多数时间在计算上，称为计算密集型；而某些进程在等待I/O上花费了绝大多数时间，称为I/O密集型。

#### 何时调度

第一，在创建一个新进程之后，需要决定是运行父进程还是子进程。

第二，在一个进程退出时必须做出调度决策。

第三，当一个进程阻塞在I/O和信号量上或由于其他原因阻塞时，必须选择另一个进程运行。

第四，在一个**I/O中断**发生时，必须做出调度决策。如果中断来自I/O设备，而该设备现在完成了工作，某些被阻塞的等待该I/O的进程就成为了可运行的就绪进程了。是否让新就绪的进程运行，这取决于调度程序的决定，或者让中断发生时运行的进程继续运行，或者应该让其他进程运行。

## 3、存储管理

### 一种存储器抽象：地址空间

把物理地址暴露给进程会带来下面几个严重问题。第一，如果用户进程可以寻址内存的每个字节，它们就可以很容易地（故意地或偶然地）破坏操作系统，从而是系统慢慢地停止运行。第二，要想同时运行多个程序是很困难的。

#### 地址空间的概念

要保证多个应用程序同时处于内存中并且不互相影响，则需要解决两个问题：**保护和重定位**。

此时，创造一个新的内存抽象：地址空间，成为了很好的选择。就像进程的概念创造了一类抽象的CPU以运行程序一样，地址空间为程序创造了一种抽象的内存。地址空间是一个进程可用于寻址内存的一套地址集合。每个进程都有一个自己的地址空间，并且这个地址空间独立于其他进程的地址空间（除了在一些特殊情况下进程需要共享它们的地址空间外）。

##### 基址寄存器和界限寄存器

这个简单的解决办法使用一种简单的**动态重定位**。它所做的是简单地**把每个进程的地址空间映射到物理内存的不同部分**。

使用基址寄存器和界限寄存器是给每个进程提供私有地址空间的非常容易的方法，因为**每个内存地址在送到内存之前，都会自动先加上基址寄存器的内容**。

使用基址寄存器和界限寄存器重定位的缺点是，**每次访问内存都需要进行加法和比较运算**。

##### 交换技术

有两种处理内存超载的通用方法。最简单策略的是交换技术（另一种策略是虚拟内存，该策略可以**使程序在只有一部分被调入内存的情况下运行**），即把一个进程完整调入内存，使该进程运行一段时间，然后把它存回磁盘。

![](http://oklbfi1yj.bkt.clouddn.com/%E3%80%8A%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E3%80%8B/9.PNG)

开始时内存中只有进程A。之后创建进程B和C或者从磁盘将它们换入内存。图3-4d显示A被交换到磁盘。然后D被调入，B被调出，最后A再次被调入。

交换技术会在内存中产生多个空闲区，可以通过把所有进程尽可能向下移动，有可能将这些小的空闲区合成一大块。该技术称为内存紧缩。这个操作通常不进行，因为它要耗费大量的CPU时间。例如，一台有1GB内存的计算机可以每20ns复制4个字节，它紧缩全部内存大约要花费5s。

### 虚拟内存

尽管基址寄存器和界限寄存器可以用于创建地址空间的抽象，还有另一个问题需要解决：管理软件的膨胀。需要运行的程序往往大到内存无法容纳，而且必然需要系统能够支持多个程序同时运行。

虚拟内存的基本思想是：每个程序拥有自己的地址空间，这个空间被分割成多个块，每一块称作一页或页面。每一页有连续的地址范围。这些页被映射到物理内存，但并不是所有的页都必须在内存中才能运行程序。**当程序引用到一部分在物理内存中的地址空间时，由硬件立刻执行必要的映射**。**当程序引用到一部分不在物理内存中的地址空间时，由操作系统负责将缺失的部分装入物理内存并重新执行失败的指令**。

虚拟内存很适合在多道程序设计系统中使用，许多程序的片段同时保存在内存中。**当一个程序等待它的一部分读入内存时，可以把CPU交给另一个进程使用**。

**由程序产生的这些地址称为虚拟地址**（所以**虚拟存储器的最大容量与计算机地址寄存器的位数有关**），它们构成一个虚拟地址空间（在磁盘上，也就是相当于对磁盘进行了地址的划分）。在没有虚拟内存的计算机上，系统直接将虚拟地址送到内存总线上，读写操作使用具有同样地址的物理内存字；而在使用虚拟内存的情况下，虚拟地址不是被直接送到内存总线上，而是送到内存管理单元（MMU），MMU把虚拟地址映射为物理地址。

![](http://oklbfi1yj.bkt.clouddn.com/%E3%80%8A%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E3%80%8B/10.PNG)

映射的方式：

![](http://oklbfi1yj.bkt.clouddn.com/%E3%80%8A%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E3%80%8B/11.PNG)

虚拟地址空间按照固定大小划分成称为页面的若干单元。在物理内存中对应的单元称为页框。页面和页框的大小通常是一样的，在上图中，页面和页框大小都是4KB。现有系统常用的页大小一般从512B（字节）到64KB（千字节）。**RAM和磁盘之间的交换总是以整个页面为单元进行的**。

当程序试图访问地址0时候，例如执行下面这条指令：

```assembly
MOV REG, 0
```

将虚拟地址0送到MMU。MMU看到虚拟地址落到页面0（0~4095），根据其映射结果，这一页面对应的是页框2（8192~12287），图中的最下面的那个页框是页框0，因此MMU把地址变换为8192，并把地址8192送到总线上。而内存对MMU一无所知，它只看到一个读或写地址8192的请求并执行它。MMU从而有效地把所有从0~4095的虚拟地址映射到8192~12287的物理地址。

通过恰当地设置MMU，可以把16个虚拟页面映射到个页框中的任何一个。但是这并没有解决虚拟地址空间比物理内存大的问题。在图3-9中只有8个物理页框，于是只有8个虚拟页面被映射到了物理内存中。图中用叉号表示的其他页并没有被映射。

当程序访问了一个未映射的页面，例如执行指令：

```assembly
MOV REG, 32780
```

将会发生什么情况呢？虚拟页面8（从32768）的第12个字节所对应的物理地址是什么呢？MMU注意到该页面没有被映射（在图中用叉号表示），于是使CPU陷入到操作系统，这个陷阱称为缺页中断。操作系统**找到一个很少使用的页框**且把它的内容写入磁盘（如果它不在磁盘上）（写入的原因是这些内容可能被修改了，需要保存起来）。**随后把需要访问的页面读到刚才回收的页框中，修改映射关系**，然后重新启动引起陷阱的指令。

发生缺页中断时，操作系统必须在内存中选择一个页面并将其换出内存，以便为即将调入的页面腾出空间。**如果要换出的页面在内存中驻留期间已经被修改过，就必须把它写回磁盘以更新该页面在磁盘上的副本（通过映射关系可以找到页面在磁盘上的位置）；如果该页面没有被修改过（如果一个包含程序正文的页面，它是只读的），那么它在磁盘上的副本已经是最新的，不需要回写。直接用调入的页面覆盖掉被淘汰的页面就可以了**。

#### 共享页面

在大型多道程序设计系统中，几个不同的用户同时运行同一个程序是很常见的。显然，由于避免了在内存中有一个页面的两份副本，共享页面效率更高。这里存在一个问题，即并不是所有的页面都适合共享。特别地，那些只读的页面（诸如程序文本）可以共享，但是数据页面则不能共享。

#### 内存映射文件

这种机制的思想是：进程可以通过发起一个系统调用，将一个文件映射到其虚拟地址空间的一部分。在多数实现中，**在映射共享的页面时不会实际读入页面的内容，而是在访问页面时才会被每次一页地读入**，磁盘文件则被当作后备存储。**当进程退出或显式地解除文件映射时，所有被改动的页面会被写回文件中**。

内存映射文件提供了一种I/O的可选模型。可以把一个文件当作一个内存中的大字符数组来访问，而不用通过读写操作来访问这个文件。

如果两个或两个以上的进程同时映射了同一个文件，它们就可以通过共享内存来通信。**一个进程在共享内存上完成了写操作，此刻当另一个进程在映射到这个文件的虚拟地址空间上执行读操作时，它就可以立刻看到上一个进程写操作的结果**。因此，这个机制提供了一个进程之间的**高带宽通道**。

## 4、文件系统

文件是进程创建的信息逻辑单元。一个磁盘一般含有几千甚至几百万个文件，每个文件是独立于其他文件的。我们可以**把每个文件看成一种地址空间**。

文件是受操作系统管理的。

### 文件

#### 文件命名

在某些系统中（如UNIX），文件扩展名只是一种约定，操作系统并不强迫采用它。名为file。txt的文件**也许是**文本文件，这个文件名在于提醒所有者，而不是表示传送什么信息给计算机。但是另一方面，C编译器可能要求它编译的文件以`.c`结尾，否则它会拒绝编译。

#### 文件属性

![](http://oklbfi1yj.bkt.clouddn.com/%E3%80%8A%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E3%80%8B/12.PNG)



#### 文件操作

##### open

在使用文件之前，必须先打开文件。open调用的目的是：把文件属性和磁盘地址表装入内存，便于后续调用的快速存取。

##### close

存取结束后，不再需要文件属性和磁盘地址，这时应该关闭文件以释放内部表空间。很多系统**限制进程打开文件的个数，以鼓励用户关闭不再使用的文件**。

#### 文件的实现

##### 连续分配

最简单的分配方案是把每个文件作为一连串连续数据块存储在磁盘上。所以，在块大小为1KB的磁盘上，50KB的文件要分配50个连续的块。对于块大小为2KB的磁盘，将分配25个连续的块。

举个例子：

![](http://oklbfi1yj.bkt.clouddn.com/%E3%80%8A%E7%8E%B0%E4%BB%A3%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E3%80%8B/13.PNG)

这里列出了头40块，从左面从0块开始。初始状态下，磁盘是空的。接着，从磁盘开始处（块0）













































