# 深入理解计算机系统

## 1、计算机系统漫游

### 二进制位

系统中**所有的信息**--包括磁盘文件、存储器中的程序、存储器中存放的用户数据以及网络上传送的数据，**都是由一串位表示的**。

### 编译系统

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/1.PNG)

#### 预处理阶段

预处理器（cpp）根据以字符`#`开头的命令，修改原始的C程序。例如加入`#include <stdio.h>`命令告诉预处理器读取系统头文件`stdio.h`的内容，并把它直接插入到程序文本中。结果就得到了另一个C程序，通常是以`.i`作为文件扩展名。

#### 编译阶段

编译器把文本文件`hello.i`翻译成文本文件`hello.s`，它是一个汇编语言程序。汇编语言是非常有用的，因为它为不同的高级语言的不同编译器提供了通用的输出语言。例如C编译器和Fortran编译器产生的输出文件用的都是一样的汇编语言。

#### 汇编阶段

汇编器将`hello.s`翻译成机器语言指令。

#### 链接阶段

链接器把那些之前先编译好了的目标文件与`hello.o`程序合并，变成一个可执行文件。而这个可执行文件可以被加载到内存中，由系统执行。

### 处理器读并解释存储在存储器中的指令

此刻，`hello.c`源程序已经被编译系统翻译成了可执行目标文件`hello`，并存放在磁盘上。要想在Unix系统上运行该可执行文件，我们将它的文件名输入到外壳（shell）的应用程序中：

```shell
uninx> ./hello
hello, world
unix>
```

**外壳是一个命令行解释器，它输出一个提示符，等待你输入一个命令行，然后执行这个命令**。如果该命令行的第一个单词不是一个内置的外壳命令，那么外壳就会假设这是一个可执行文件的名字，它将加载并运行这个文件。所以，在此例中，外壳将加载并运行`hello`程序，然后等待程序终止。`hello`程序在屏幕上输出它的信息，然后终止。外壳随后输出一个提示符，等待下一个输入的命令行。

#### 系统的硬件组成

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/2.png)

##### I/O设备

输入/输出（I/O）设备是**系统与外部世界的联系管道**。

示例系统中包括4个I/O设备：作为用户输入的键盘和鼠标，作为用户输出的显示器，以及**用于长期存储数据和程序的磁盘驱动器**（简单地说就是**磁盘**）。最初，可执行程序`hello`就存放在磁盘。

每个I/O设备都通过一个控制器或适配器与I/O总线相连。它们的功能都是**在I/O总线和I/O设备之间传递信息**。

##### 处理器

**处理器是解释（或执行）存储在主存中指令的引擎**。处理器的核心是一个字长的存储设备（或寄存器），称为**程序计数器**。**在任何时刻，PC都指向主存中的某条机器语言指令（即含有该条指令的地址）**

##### 运行hello程序

初始时，外壳程序执行它的指令，等待我们输入一个命令。当我们在键盘上输入字符串`./hello`后，外壳程序将字符逐一读入寄存器，再把它存放到存储器中。如图：

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/3.PNG)

当我们在键盘上桥下回车键时，外壳程序就知道我们已经结束了命令的输入。然后外壳程序执行一系列指令来加载可执行的`hello`文件，**将`hello`目标文件中的代码和数据从磁盘复制到主存。**数据包括最终会被输出的字符串`"hello, world\n"`。

利用直接存储器采取（DMA）技术，数据可以不通过处理器而直接从磁盘到达主存。如图：

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/4.PNG)

#### 高速缓存至关重要

系上面的简单示例揭示了一个重要的问题，即系统花费了大量的时间把信息从一个地方挪到另一个地方。`hello`程序的机器指令最初是存放在磁盘上的，当程序加载时，它们被复制到主存；当 处理器运行程序时，指令又从主存复制到处理器。相似地，数据串`hello, world\n`初始时在磁盘上，然后复制到主存，最后从主存上复制到显示设备。从程序员的角度来看，这些复制就是开销，减缓了程序“真正”的工作。因此，系统设计者的一个主要目标就是使这些复制操作尽可能快地完成。

系统可以获得一个很大的存储器，同时访问速度也很快，是因为利用了高速缓存的局部性原理，即程序具有访问局部区域里的数据和代码的趋势。**让高速缓存里存放可能经常访问的数据的方法。**

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/5.PNG)

#### 操作系统管理硬件

当外壳加载和运行`hello`程序，以及`hello`程序输出自己的消息时，外壳和`hello`程序都没有直接访问键盘、显示器、磁盘或者主存。而是依靠**操作系统**提供服务。可以**把操作系统看成是应用程序和硬件之间插入的一层软件**。**所有应用程序对硬件的操作尝试都必须通过操作系统**。

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/6.PNG)

##### 操作系统的两个基本功能

1、防止硬件被失控的应用程序滥用

2、向应用程序提供简单一致的机制来控制复杂而又通常大相径庭的低级硬件设备。

操作系统通过几个基本的抽象概念（进程、虚拟存储器和文件）来实现这两个功能。如图：

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/7.PNG)

**文件是对I/O设备的抽象表示，虚拟存储器是对主存和磁盘I/O设备的抽象表示，进程则是对处理器、主存和I/O设备的抽象表示。**

##### 上下文

操作系统保持跟踪进程运行所需的所有状态信息。这种状态，就是上下文，它包括许多信息，例如PC（指向需要执行的指令）和寄存器文件的当前值，以及主存的内容。

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/8.PNG)

例如，有两个并发进程：外壳进程和`hello`进程。起初，只有外壳进程在运行，即等待命令行上的输入。当我们让它运行`hello`程序时，外壳通过调用一个专门的函数，即系统调用，来执行我们的请求，系统调用会将控制权传递给操作系统。操作系统保存外壳进程的上下文，创建一个新的`hello`进程及其上下文，然后将控制权传递给新的`hello`进程。`hello`进程终止后，操作系统恢复外壳进程的上下文，并将控制权传回给它，外壳将继续等待下一个命令行输入。

##### 线程

多线程之间比多进程之间更容易共享数据，也因为线程一般来说都比进程更高效。

##### 虚拟存储器

虚拟存储器是一个抽象概念（对程序存储器的抽象），它为每个进程提供了一个假象，即每个进程都在独占地使用主存。**每个进程看到的是一致的存储器，称为虚拟地址空间**。（也就是说每个进程都是使用同一套虚拟存储器的模型）。图中的地址是从下往上增大的。

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/9.PNG)

**操作系统负责管理虚拟地址空间，将虚拟地址空间翻译成实际处理器存储器中的物理地址。**程序存储器用虚拟地址来寻址，原因是为了保证合法性（在任意给定的时刻，只认为有限的一部分虚拟地址是合法的）。例如，虽然IA32的32位地址理论上可以寻址4GB的地址范围，但是通常一个程序你会访问几兆字节（即**并不是真的支持完全地址范围**）。

**程序代码和数据**

对于所有的进程来说，代码是从同一固定地址开始，紧接着的是和C全局变量相对应的数据位置。代码和数据区是直接按照可执行目标文件的内容初始化的，在示例中，就是可执行文件`hello`。

**堆**

代码和数据区是在进程一开始运行时就被规定了大小，与此不同，**堆可以在运行时动态地扩展和收缩**。

**共享库**

大约在地址空间的中间部分是一块用来存放向C标准库和数学库这样共享的代码和数据的区域。

**栈**

位于用户虚拟地址空间顶部的是用户栈，编译器用它来实现函数调用。和堆一样，用户栈在程序执行期间可以动态地扩展和收缩。特别是每次我们调用一个函数时，栈就会增长；从一个函数返回时，栈就会收缩。

**内核虚拟存储器**

内核总是驻留在内存中，是操作系统的一部分。地址空间顶部的区域是为内核保留的，**不允许应用程序读写这个区域的内容或者之间调用内核代码定义的函数。**

##### 文件

文件就是字节序列，仅此而已。每个I/O设备，包括磁盘、键盘、显示器，甚至网络（本质上是一种I/O设备），都可以视为文件。

#### 并发

##### 多处理器

多处理器的使用可以从两个方面提高系统性能。首先，它减少了在执行多个任务时模拟并发的需要（即进程间的切换）。其次，它可以使应用程序运行得更快。当然，这必须要求程序是以多线程方式来书写的，这些线程可以并行地高效执行。

##### 多核处理器

多核处理器是将多个CPU（称为“核”）集成到了一个集成电路芯片上。

##### 超线程

有时称为**同时多线程**。常规的处理器需要大约20000个时钟周期做不同线程间的转换，而**超线程的处理器可以在单个周期的基础上决定要执行哪一个线程**。这使得CPU能够更好地利用它的处理资源。

### 四个抽象

**文件**是对I/O的抽象

**虚拟存储器**是对程序存储器的抽象

**进程**是对一个**正在运行的程序**的抽象

**虚拟机**是对整个计算机（包括操作系统、处理器和程序）的抽象

## 2、信息的表示和处理

虽然浮点数可以编码一个较大的数值范围，但是这种表示只是近似的。

### 信息存储

大多数计算机使用8位的块，或者字节（byte），作为最小的可寻址的存储器单位，而不是在存储器中访问单独的位。**机器级程序将存储器视为一个非常大的字节数组**，称为**虚拟存储器**。存储器的每个字节都由一个唯一的数字来标识，称为它的地址，所有可能地址的集合称为虚拟地址空间。

编译器和运行时系统是如何将存储器空间划分为更可管理的单元，以存放不同的程序对象，即程序数据、指令和控制信息。可以用各种机制来分配和管理程序不同部分的存储。这种管理完全是在虚拟地址空间里完成的。**例如，C语言中一个指针的值（无论它是指向一个整数、一个结构或是某个其他程序对象）都是某个存储块第一个字节的虚拟地址。**C编译器还把每个指针和类型信息联系起来，这样就可以根据指针值的类型，生成不同的机器级代码来访问存储在指针所指位置处的值。**尽管C编译器维护着这个类型信息，但是它生成的实际机器级程序并不包含关于数据类型的信息。**

### 可移植性

程序员应该力图使他们的程序在不同的机器和编译器上是可移植的。**可移植的一个方面就是使程序对不同数据类型的确切大小不敏感**。在以前，许多程序的编写都假设计算机是32位机器对应的字节分配。随着64位机器的日益普及，在将这写程序移植到新机器上时，许多隐藏的对字节的依赖性就会显现出来，成为错误。比如，**许多程序员假设一个声明为`int`类型的程序对象能被用来存储一个指针。这在大多数32位机器上能正常工作，但是在一台64位机器上却会导致问题**。

使用C语言的运算符`sizeof`来确定对象使用的字节数。一般来说，表达式`sizeof(T)`返回存储一个类型为T的对象所需要的字节数。使用`sizeof`，而不是一个固定的值，是向编写在不同机器类型上可移植的代码迈进了一步。

### 类型转换

字节顺序变得可见的第三种情况是当编写规避正常的类型系统的程序时。在C语言中，可以使用强制类型转换来允许以一种数据类型引用一个对象，而这种数据类型与创建这个对象时定义的数据类型不同。**大多数应用编程都强烈不推荐这种编程技巧，但是它们对系统级编程来说是非常有用的，甚至是必需的。**

### 使用typede命名数据类型

C语言中的typedef声明提供了一种给数据类型命名的方式。这能够极大地改善代码的可读性，因为深度嵌套的类型声明很难读懂。

## 3、程序的机器级表示

通常情况下，现代的优化编译器产生的代码至少与一个熟练的汇编语言程序员手工编写的代码一样有效。**最大的优点是，用高级语言编写的程序可以在很多不同的机器上编译和执行，而汇编代码则是与特定机器密切相关**。

程序员学习汇编代码的需求随着时间的推移也发生了变化，开始时只要求程序员能直接用汇编语言编写程序，现在则是要求他们能够阅读和理解编译器产生的代码。

我们必须了解典型的编译器在将C程序结构变换成机器代码时所做的转换。相对于C代码表示的计算操作，**优化编译器**能够重新排列执行顺序，消除不必要的计算，用快速操作替换慢速操作，甚至**将递归计算变换成迭代计算**。

### 程序编码

假设一个C程序，有两个文件`p1.c`和`p2.c`。我们在一台IA32机器上，用Unix命令行编译这些代码如下：

```shell
unix> gcc -o1 -o p p1.c p2.c
```

命令gcc指的就是GCC C编译器。因为这是Linux上默认的编译器，我们也可以简单地用cc来启动它。编译选项`o1`告诉编译器使用第一个优化。通常，提高优化级别会使最终程序运行得更快，但是编译时间可能会变长，用调试工具对代码进行调试会更困难。正如我们还会看到的，使用更高级别的优化产生的代码会严重改变形式，以至于产生的机器代码和初始源代码之间的关系非常难以理解。从得到的程序性能方面考虑，第二级（选项-o2指定）被认为是较好的选择。

gcc命令调用了一些列程序，将源代码转化成可执行代码。首先，C预处理器扩展源代码，插入所有用`#include`命令指定的文件，并扩展所有用`#define`声明指定的宏。然后，编译器产生两个源代码的汇编代码，名字分别为`p1.s`和`p2.s`。接下来，汇编器将汇编代码转化成二进制目标代码，文件名为`p1.o`和`p2.o`。**目标代码是机器代码的一种形式，它包含所有指令的二进制表示，但是还没有填入地址的全局值**。最后，链接器将两个目标代码文件与实现库函数（例如printf）的代码合并，并产生最终的可执行代码文件`p`。**可执行代码是我们要考虑的机器代码的第二种形式，也是处理器执行的代码格式**。

生成实际可执行的代码需要对一组目标代码文件运行链接器，而这一组目标代码文件中必须含有一个`main`函数。

### 过程

一个过程调用包括将数据（以过程参数和返回值的形式）和控制从代码的一部分传递到另一部分。另外，它还必须在进入时为过程的局部变量分配空间，并在**退出时释放这些空间**。

大多数机器，包括IA32，只提供转移控制到过程和从过程中转移出控制这种简单的指令。数据传递、局部变量的分配和释放通过操纵程序栈来实现。

#### 栈帧结构

IA32程序用程序栈来支持过程调用。机器用栈来传递过程参数、存储返回信息、保存寄存器用于以后恢复，以及本地存储。为单个过程分配的那部分栈称为栈帧（stack frame）。

![](http://oklbfi1yj.bkt.clouddn.com/%E7%90%86%E8%A7%A3%E6%B1%87%E7%BC%96%E4%BB%A3%E7%A0%81%E5%92%8C%E5%AE%83%E4%B8%8E%E9%AB%98%E7%BA%A7%E8%AF%AD%E8%A8%80%E7%9A%84%E8%81%94%E7%B3%BB/10.PNG)

栈帧的最顶端以两个指针界定，寄存器`%ebp`为**帧指针**，而寄存器`%esp`为**栈指针**。当程序执行时，**栈指针可以移动，因此大多数信息的访问都是相对于帧指针的**。

栈向低地址方向增长，而`%esp`指向栈顶元素。将栈指针的值（指的是地址大小）减小适当的值可以分配没有指定初始值的数据的空间。类似地，可以通过增加栈指针（指的是地址大小）来释放空间。

假设过程P（调用者）调用过程Q（被调用者），则Q的参数放在P的栈帧中。另外，当P调用Q时，**P中的返回地址被压入栈中，形成P的栈帧的末尾**。**返回地址就是当程序从Q返回时应该继续执行的地方**。Q的栈帧从保存的帧指针的值（例如%ebp）开始，后面是保存的其他寄存器的值。

过程Q也用栈来保存其他不能存放在寄存器中的局部变量。原因如下：

1、没有足够多的寄存器存放所有的局部变量。

2、有些局部变量是数组或结构，因此必须通过数组或结构引用来访问。

3、要对一个局部变量使用地址操作符`&`，我们必须能够为它生成一个地址。

#### 转移控制

![](http://oklbfi1yj.bkt.clouddn.com/%E7%90%86%E8%A7%A3%E6%B1%87%E7%BC%96%E4%BB%A3%E7%A0%81%E5%92%8C%E5%AE%83%E4%B8%8E%E9%AB%98%E7%BA%A7%E8%AF%AD%E8%A8%80%E7%9A%84%E8%81%94%E7%B3%BB/11.PNG)

`call`指令有一个目标，即指明被调用过程起始的指令地址。同跳转一样，调用可以是直接的，也可以是间接的。在汇编代码中，直接调用的目标是一个标号，而间接调用的目标是`*`后面跟一个操作数提示符。

`call`指令的效果是将返回地址入栈，并跳转到被调用过程的起始地址。**返回地址是在程序中紧跟在`call`后面的那条指令的地址**，这样当被调用过程返回时，执行会从此处继续。`ret`指令从栈中弹出地址，并跳转到这个位置。正确使用这条指令，可以使栈做好准备，栈指针要指向前面`call`指令存储返回地址的位置。

`call`指令将控制转移到一个函数的起始，而`ret`指令返回到`call`指令后的那条指令。

#### 寄存器使用惯例

**程序寄存器组是唯一能被所有过程共享的资源**。虽然在给定时刻只能有一个过程是活动的，但是我们必须保证当一个过程（调用者）调用另一个过程（被调用者）时，被调用者不会覆盖某个调用者稍后会使用的寄存器的值。为此，IA32采用了一组统一的寄存器使用惯例，所有的过程都必须遵守，包括程序库中的过程。

根据惯例，寄存器`%eax`、`%edx`和`%ecx`被划分为**调用者保存**寄存器。当过程P调用Q时，Q可以覆盖这些寄存器，而不会破环任何P所需要的数据。另一方面，寄存器`%ebx`、`%esi`和`%edi`被划分为**被调用者保存**寄存器。这意味着Q必须在覆盖这些寄存器的值之前，先把它们保存到栈中，并在返回前恢复它们，因为P（或某个更高层次的过程）可能会在今后的计算中需要这些值。此外，根据这里描述的惯例，必须保持寄存器`%ebp`和`%esp`。

作为一个示例，考虑下面这段代码：

```c++
int P(int x) {
	int y = x * x;
	int z = Q(y);
	return y + z;
}
```

过程P在调用Q之前计算y，但是它必须保证y的值在Q返回后是可用的。有以下两种方式可以实现：

1、可以在调用Q之前，将y的值存放在自己的栈帧中；当Q返回时，过程P就可以从栈中取出y的值。换句话说，调用者P保存这个值。

2、可以将y的值保存在**被调用者保存**寄存器中。如果Q，或任何其他Q调用的程序，想使用这个寄存器，它必须将这个寄存器的值保存在栈帧中，并在返回前恢复该值（换句话说，**被调用者保存**这个值）。**当Q返回到P时，y的值会在被调用者保存寄存器中**，**或者是因为寄存器根本就没有改变，或者是因为它被保存并恢复了**。

只要对于哪个函数负责保存哪个值有一致的约定，上述两种惯例都能工作。这两种方法IA32都采用，将寄存器分为一组为**调用者保存**，另一组为**被调用者保存**的。

#### 过程示例

```c++
int swap_add(int* xp, int* yp) {
	int x = *xp;
	int y = *yp;

	*xp = y;
	*yp = x;

	return x + y;
}

int caller() {
	int arg1 = 534;
	int arg2 = 1057;
	int sum = swap_add(&arg1, &arg2);
	int diff = arg1 - arg2;

	return sum * diff;
}
```

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/12.PNG)

`caller`的栈帧包括变量`arg1`和`arg2`的存储，这些变量必须存在栈中，因为我们必须为它们生成地址。接下来的这段汇编代码来自`caller`编译过的编译版本，说明他如何调用`swap_add`：

```assembly
caller:
    push1    %ebp              ;save old %ebp
    movl     %ebp              ;set %ebp as frame pointer
    subl     $24, %esp         ;allocate 24 bytes on stack
    movl     $534, -4(%ebp)    ;set arg1 to 534
    movl     $1057, -8(%ebp)   ;set arg2 to 1057
    leal     -8(%ebp), %eax    ;compute &arg2
    movl     %eax, 4(%esp)     ;store on stack
    leal     -4(%ebp), %eax    ;compute &arg1
    movl     %eax, (%esp)      ;store on stack
    call     swap_add          ;call the swap_add function
```

这段代码保存了`%ebp`的一个副本，将`%ebp`设置为栈帧的开始位置（第2~3行）。然后将栈指针减去24，从而在栈上分配24个字节（因为栈是向低地址生长的）。将`arg1`和`arg2`分别初始化为534和1057（第5~6行），计算`&arg2`和`&arg1`的值并存储到栈上，形成函数`swap_add`的参数（第7~10行）。将这些参数存储到相对于栈指针偏移量为0和+4的地方，留待稍后`swap_add`访问。然后调用`swap_add`。分配栈帧的24个字节中，8个用于局部变量，**8个用于向`swap_add`传递参数**，还有8个未使用。

`swap_add`编译过的代码有三个部分：“建立”部分，初始化栈帧：“主体”部分，执行过程的实际计算；“结束”部分，恢复栈的状态，以及过程返回。

下面是`swap_add`的建立代码。回想一下，在到达代码的这个部分之前，`call`指令已经将返回地址压入栈中。

```assembly
swap_add:
    push1 %ebp
    movl %esp, %ebp
    push1 %ebx
```

函数`swap_add`需要用寄存器`%ebx`作为临时存储。因为这是一个被调用者保存寄存器，它会将旧值压入栈中，这是栈帧建立的一部分。

寄存器`%ebp`已经移动了，作为`swap_add`的帧指针。

下面是`swap_add`的主体代码：

```assembly
movl 8(%ebp), %edx    ;Get xp
movl 12(%ebp), %ecx   ;Get yp
movl (%edx), %ebx     ;Get x
movl (%ecx), %eax     ;Get y
movl %eax, (%edx)     ;Store y at xp
movl %ebx, (%ecx)     ;Store x at yp
addl %ebx, %eax       ;Return value = x + y
```

这段代码从`caller`的栈帧中取出它的参数。因为帧指针已经移动，这些参数的位置也从相对于`%esp`的旧值+4和0的位置移到了相对于`%ebp`的新值+12和+8的位置。注意，**变量x和y的和存放在寄存器`%eax`中作为返回值传递**。

下面是`swap_add`的结束代码：

```assembly
popl %ebx    ;Restore %ebx
popl %ebp    ;Restore %ebp
ret          ;Return
```

这段代码恢复寄存器`%ebx`和`%ebp`的值，**同时也重新设定栈指针使它指向存储的返回值，这样ret指令就可以将控制转移回`caller`**。

下面的`caller`中的代码紧跟在调用`swap_add`的指令后面：

```assembly
movl   -4(%ebp), %edx
subl   -8(%ebp), %edx
imull  %edx, %eax
leave
ret
```

为了计算diff，这段代码从栈中取出`arg1`和`arg2`的值，并将寄存器`%eax`当作从`swap_add`的返回值。可以观察到，leave指令的使用在返回前，既重置了栈指针，也重置了帧指针。我们在代码示例中已经看到，GCC产生的代码有时候会使用`leave`指令来释放栈帧，而有时会使用一个或者两个`popl`指令。

从这个示例中我们可以看到，编译器根据一组很简单的惯例来产生管理栈结构的代码。参数在栈上传递给函数，可以从栈中用相对于`%ebp`的正偏移量来访问它们。可以用push指令或是从栈指针减去偏移量来在栈上分配空间。

### 数组分配和访问

C语言中的数组是一种将标量数据聚集更大数据类型的方式。C语言实现数组的方式非常简单，因此很容易翻译成机器代码。C语言一个不同寻常的特点是可以产生指向数组中元素的指针，并对这些指针进行运算。这机器代码中，这些指针会被翻译成地址计算。

### 数据对齐

许多计算机系统对基本数据类型合法地址做出了一些限制，要求某种类型对象的地址必须是某个值K（通常是2、4或8）的倍数。这种对齐限制**简化了形成处理器和存储器系统之间接口的硬件设计**。例如，假设一个处理器总是从存储器中取出8个字节，则地址必须为8的倍数。如果我们能保证将所有的`double`类型数据的地址对齐成8的倍数，那么就可以用一个存储器操作来读或者写值了。**否则，我们可能需要执行两次存储器访问，因为对象可能被分放在两个8字节存储器块中**。

处理器中的存储器接口被设计成读或者写对齐的块。

### 指针

#### 每个指针都有一个值

这个值是某个指定类型对象的地址。特殊的NULL（0）值表示该指针没有指向任何地方。

#### 指针用&运算符创建

#### 强制类型转换

将指针从一种类型强制转换成另一种类型，只改变它的类型，而不改变它的值。

它的效果是改变指针运算的伸缩。

#### 存储器的越界引用和缓冲区溢出

C对于数组引用不进行任何边界检查，而且局部变量和状态信息（例如保存的寄存器值和返回地址），都存放在栈中。这两种情况结合到一起就可能导致严重的程序错误，对越界的数组元素的写操作会破坏存储在栈中的状态信息。当程序使用这个被破坏的状态，试图重新加载寄存器或执行`ret`指令时，就会出现很严重的错误。

一种特别常见的状态破坏称为缓冲区溢出。通常，在栈中分配某个字节数组来保存一个字符串，但是在字符串的长度超出了为数组分配的空间。

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/13.PNG)

随着字符数数量的增加，破坏的状态越来越多。根据影响状态部分的不同，程序出现以下几种不同的错误：

- 如果破坏了存储在`%ebx`的值，那么这个寄存器就不能正确地恢复，因此虽然应该由被调用者来保存好这个值，但是调用者也不能依靠这个寄存器的完整性。
- 如果破坏了存储`%ebp`的值，那么这个寄存器就不能正确地恢复，因此调用者就不能正确地引用它的局部变量或者参数。
- 如果破坏了存储的返回地址，那么`ret`指令会使程序跳转到完全意想不到的地方。


#### 对抗缓冲区溢出攻击

缓冲区溢出攻击的普遍发生，给计算机系统造成了许多的麻烦。现代的编译器和操作系统已经实现了许多机制，以避免遭受这样的攻击，限制入侵者通过缓冲区溢出攻击获得系统控制的方式。

##### 1、栈随机化

为了在系统中插入攻击代码，攻击者不但要插入代码，还需要插入指向这段代码的指针，这个指针也是攻击字符串的一部分。产生这个指针需要知道这个字符串放置的栈地址。在过去，程序的栈地址非常容易预测。**对于所有同样程序和操作系统版本的系统来说，在不同的机器之间，栈的位置是相当固定的**。因此，如果攻击者可以确定一个常见的Web服务器所使用的栈空间，就可以设计一个在多个机器上都能实施的攻击。

栈随机化的思想使得栈的位置在程序每次运行时都有变化。因此，即使许多机器都运行同样的代码，它们的栈地址都是不同的。实现的方式是：程序开始时，在栈上分配指定字节数量的空间。程序不使用这段空间，但是它会导致程序每次执行时后续的栈位置发生变化。分配的范围n必须足够大，才能获得足够多样的栈地址变化，但是又要足够小，不至于浪费程序太多的空间。

下面的代码是一种确定“典型的”栈地址的方法：

```c++
int main () {
    int local;
    printf("local at %p\n", &local);
    
    return 0;
}
```

这段代码只是简单地打印出`main`函数中局部变量的地址。在32位Linux上运行这段代码10000次，这个地址的变化范围为`0xff7fa7e0`到`0xffffd7e0`，范围大小大约是2的23次方。作为对比，在一个版本比较老的Linux系统上运行这段代码，每次输出的地址都是一样的。

##### 2、栈破坏检测

检测何时栈已经被破坏。因为在图（3-31）中看到，破坏通常发生在当超越局部缓冲区的边界时。在C语言中，没有可靠的方法来防止对数组的越界写。但是，我们能够在发生了越界写的时候，在没有造成任何有害结果之前，尝试检测到它。

GCC在产生的代码中加入了一种栈保护者机制，用来检测缓冲区越界。其思想是在栈帧中任何局部缓冲区与栈状态之间存储一个特殊的金丝雀值。如图：

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/14.PNG)

这个金丝雀值，也称为哨兵，是在程序每次运行时随机产生的，因此，攻击者没有简单的办法能够知道它是什么。在恢复寄存器状态和从函数返回之前，程序检查这个金丝雀值是否被该函数的某个操作或者该函数调用的某个函数的某个操作改变了。如果是，那么程序异常中止。

##### 3、限制可执行代码区域

限制那些能够存放可执行代码的存储器区域。在典型的程序中，只有保存编译器产生的代码的那部分存储器才需要是可执行的。其他部分可以被限制为只允许读和写。硬件支持多种形式的存储器保护，能够指明用户程序和操作系统内核所允许的访问形式。许多系统允许控制三种访问形式：读（从存储器读数据）、写（存储数据到存储器）和执行（将存储器的内容看作是机器级代码）。**以前，x86体系结构将读和执行访问控制合并成一个1位的标志，这样任何被标记为可读的页也都是可执行的**。栈必须是既可读又可写的，因而栈上的字节也都是可执行的。已经实现的很多机制，能够限制一些页是可读但是不可执行的，然而这些机制通常会带来严重的性能损失。

现在的处理器的内存保护引入了“NX”（No-eXecute）位，将读和执行访问模式分开。有了这个特性，栈可以被标记为可读和可写，但是不可执行，检查页是否可执行由硬件来完成，效率上没有损失。

### 算术指令

当不同大小的操作数混合在一起时，GCC必须选择正确的算术指令、符号扩展和零扩展的组合。这些指令的组合依赖于类型转换和对不同操作数大小的指令的行为。例如：

```c++
long int gfun(int x, int y) {
	long int t1 = (long)x + y;
	long int t2 = (long)(x + y);

	return t1 | t2;
}
```

假定整数是32位的，长整数是64位的，这个函数中的两个加法先后进行。因为强制类型转换的优先级高于加法，所以第3行要求x被转换成64位，由于**操作数向上看齐的原则**，y也被转换成64位。然后用64位加法计算t1的值。另一方面，第4行用32位加法计算t2，然后再将结果扩展到64位。

### 栈帧

许多编译后的函数并不需要栈帧。如果所有的局部变量都能保存在寄存器中，而且这个函数也不会调用其他函数（参考过程调用的树结构，有时称为叶子过程（leaf procedure））， 那么**需要栈的唯一原因就是用来保存返回地址**。

另一方面，使得函数可能需要栈帧的原因如下：

1、**局部变量太多**，不能都放在寄存器中。

2、有些局部变量是**数组或者结构**。

3、函数用取地址操作符（&）来计算一个局部变量的地址。

4、函数必须将栈上的某些参数传递到另一个函数。

5、在修改一个被调用者保存寄存器之前，函数需要保存它的状态。

**当上述条件中有任何一条满足时，我们发现函数编译出来的代码就会创建栈帧。**与IA32的代码不同，那里栈指针会随着值的压入和弹出不断前后移动，但是x86-64过程的栈帧通常有固定的大小，在过程开始时通过减小栈指针（寄存器%rsp）来设置。在调用过程中，栈指针保持在固定的位置，使得可以用相对于栈指针的偏移量来访问数据。因此，就不再需要IA32代码中可见的帧指针（%ebp）了。

每当一个函数（调用者）要调用另一个函数（被调用者）时，**返回地址会被压入栈中**。通常，**我们认为这是调用者栈帧的一部分**，它编码的是某种调用者的状态。但是，当控制返回到调用者时，会把这个信息从栈中弹出来，所以它不会影响调用者访问栈帧中值所使用的偏移量。

## 4、处理器体系结构

**存储器，从概念上来说就是一个很大的字节数组，保存着程序和数据**。Y86程序用虚拟地址来引用存储器位置。**硬件和操作系统软件联合起来将虚拟地址翻译成实际或物理地址**，指明数据实际保存在存储器中哪个地方。

## 5、优化程序性能

编写高效程序需要几类活动：第一，我们**必须选择一组合适的算法和数据结构**。第二，我们**必须编写出编译器能够有效优化以转换成高效可执行代码的源代码**。对于第二点，理解优化编译器的能力和局限性是很重要的。编写程序方式看上去只是一点小小的变动，都会引起编译器优化方式很大的变化。有些编程语言比其他语言容易优化得多。C语言的有些特性，例如执行指针运算和强制类型转换的能力，使得编译器很难对它进行优化。程序员经常能够以一种使编译器更容易产生高效代码的方式来编写他们的程序。第三项技术针对处理运算量特别大的计算，将一个任务分成多个部分，这些部分可以**在多核和多处理器的某种组合上并行地计算**。即使是要利用并行性，每个并行的线程都以最高性能执行也是非常重要的。

## 6、存储器层次结构

在简单模型中，存储器系统是一个线性的字节数组，而CPU能够在一个常数时间内访问每个存储器位置。虽然迄今为止这都是一个有效的模型，但是它没有反映现代系统实际工作的方式。

存储器系统是一个具有不同容量、成本和访问时间的存储设备的层次结构。CPU寄存器保存着最常用的数据。靠近CPU的小的、快速的**高速缓存存储器**作为一部分存储在相对慢速的主存储器（简称为主存）中的数据和指令的缓冲区域（现代计算机频繁地使用基于SRAM的高速缓存，试图弥补处理器-存储器之间的差距。这种方法行之有效是因为应用程序的一个称为**局部性**的基本属性）。主存暂时存放存储在容量较大的、慢速磁盘上的数据，而这些**磁盘**常常又作为存储在通过**网络连接**的其他机器的磁盘或磁带上的数据的**缓冲区域**。

如果程序需要的数据是存储在CPU寄存器中的，那么在指令的执行期间，在零个周期内就可以访问到它们。如果存储在高速缓存中，需要1~30个周期。如果存储在主存中，需要50~200个周期。而如果存储在磁盘上，需要大约几千万个周期。

### 非易失性存储器

如果断电，DRAM（动态随机存储器，用来作为主存）和SRAM（静态随机存储器，用来作为高速缓存存储器）会丢失它们的信息，从这个意义上来说，它们是**易失的**。

**闪存**是一种非易失性存储器。

**固态硬盘**是一种新型的基于闪存的磁盘驱动器，称为固态硬盘，它能够提供相对于传统旋转磁盘更快速、更强健和更低能耗的选择。

### 访问主存

数据流通过称为总线的共享电子电路在处理器和DRAM主存之间来来回回。每次CPU和主存之间的数据传送都是通过一系列步骤来完成的，这些步骤称为总线事务。**读事务从主存传送数据到CPU。写事务从CPU传送数据到主存。**（也就是说，**读和写是相对于主存来说的**）

### 计算机系统的配置示意图

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/15.PNG)

主要部件是CPU芯片、我们将称为I/O桥的芯片组（其中包括存储控制器），以及组成主存的DRAM存储器模块。这些部件由一对总线连接起来，其中一条总线是系统总线，它连接CPU和I/O桥，另一条总线是存储器总线，它连接I/O桥和主存。

考虑当CPU执行一个向下面这样的加载操作时会发生什么

```assembly
movl A, %eax
```

这里，地址A的内容被加载到寄存器`%eax`中。CPU芯片上称为总线接口的电路发起总线上的读事务。读事务是有三个步骤组成的。首先，CPU将地址A放到系统总线上。I/O桥将信号传递到存储器总线。其次，主存感觉到存储器总线上的地址信号，从存储器总线读地址，从DRAM取出数据字，并将数据写到存储器总线。I/O桥将存储器总线信号翻译成系统总线信号，然后沿着系统总线传递。最后CPU感觉到系统总线上的数据，从总线上读数据，并将数据拷贝到寄存器`%eax`。

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/16.PNG)

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/17.PNG)

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/18.PNG)

### 磁盘存储

磁盘是广为应用的保存大量数据的存储设备，存储数据的数量级可以达到几百到几千千兆字节，而基于RAM的存储器只能有几百或几千兆字节。不过，从磁盘上读信息的时间为毫秒级，从DRAM（主存）读比从磁盘读快10万倍，从SRAM（高速缓存）读比从磁盘读快100万倍。

#### 磁盘构造

**磁盘是由盘片构成**。每个盘片有两面或者称为表面，表面覆盖着磁性记录材料。盘片中央有一个可以旋转的主轴，它使得盘片以固定的旋转速率旋转。磁盘通常包含一个或多个这样的盘片，并封装在一个密封的容器（因为，在这样小的间隙里，盘面上一粒微小的灰尘都像一块巨石。如果读/写头碰到了这样的一块巨石，读/写头会停下来，撞到盘面--所谓的读/写头冲撞。因此，磁盘总是密封包装的）

每个表面是由一组称为磁道的同心圆组成的。每个磁道被划分为一组扇区。每个扇区包含相等数量的数据位（通常是512字节），这些数据编码在扇区上的磁性材料中。**扇区之间由一些间隙分隔开，这些间隙中不存储数据位。间隙存储用来标识扇区的格式化位。**

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/19.PNG)

#### 磁盘操作

磁盘用读/写头来读写存储在磁性表面的位，而读写头连接到一个传动臂一端。**通过沿着半径妯前后移动这个传动臂，驱动器可以将读/写头定位在盘面上的任何磁道上**。这样的机械运动称为**寻道**。一旦读/写头定位到了期望的磁道上，那么当磁道上的每个位通过它的下面时，读/写头可以感知到这个位的值（读该位），也可以修改这个位的值（写该位）。

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/20.PNG)

有多个盘片的磁盘针对每个盘面都有一个独立的读/写头。

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/21.PNG)

#### 对扇区的访问时间

##### 寻道时间

传动臂将读/写头定位到目标扇区所在的那个磁道上。

##### 旋转时间

一旦读/写头定位到了期望的磁道，驱动器等待目标扇区的第一个位旋转到读/写头下。

##### 传送时间

当目标扇区的第一个位位于读/写头下时，驱动器就可以开始读或者写该扇区的内容了。

##### 逻辑磁盘块

正如我们看到的那样，现代磁盘构造复杂，有多个盘面，这些盘面上有不同的记录区。为了对操作系统隐藏这样的复杂性，现代磁盘将它们的构造呈现为一个简单的视图，一个B个扇区大小的逻辑块序列，编号为0，1，...，B-1。磁盘中有一个小的硬件/固件设备，称为**磁盘控制器，维护着逻辑块号和实际（物理）磁盘扇区之间的映射关系**。

当操作系统想要执行一个I/O操作时，**例如读一个磁盘扇区的数据到主存，操作系统会发送一个命令到磁盘控制器，让它读某个逻辑块号。控制器上的固件执行一个快速表查找，将一个逻辑块号翻译成一个（盘面，磁道，扇区）的三元组，这个三元组唯一地标识了对应的物理扇区**。控制器上的硬件解释这个三元组，将读/写头移动到适当的柱面，等待扇区移动到读/写头下，将读/写头感知到的位放到控制器上的一个小缓冲区中，然后将它们拷贝到主存中。

##### 访问磁盘

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/22.PNG)

当CPU从磁盘读数据时发生的步骤：

CPU使用一种称为**存储器映射I/O**的技术来向I/O设备发出命令。在使用存储器映射I/O的系统中，**地址空间中有一块地址是为与I/O设备通信保留的**。每个这样的地址**称为一个I/O端口**。当一个设备连接到总线时，它与一个或多个端口相关联（或它被映射到一个或多个端口）

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/23.PNG)

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/24.PNG)

在磁盘控制器收到来自CPU的读命令之后，它将逻辑块号翻译成一个扇区地址，读该扇区的内容，然后**将这些内容直接传送到主存，不需要CPU的干涉**。设备可以自己执行读或者写总线事务，而不需要CPU干涉，这个过程称为直接内存访问（DMA）

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/25.PNG)

在DMA传送完成，磁盘扇区的内容被安全地存储在主存中以后，磁盘控制器通过给CPU发送一个中断信号来通知CPU。基本思想是中断会发信号到CPU芯片的一个外部引脚上。这会**导致CPU暂停它当前正在做的工作，跳转到一个操作系统例程。这个操作系统例程会记录下I/O已经完成，然后将控制返回到CPU被中断的地方**。

当CPU发起了请求之后，在磁盘执行读的时候，它通常会做些其他的工作。回想一下，一个1GHz的处理器时钟周期为1ns，在用来读磁盘的16ms时间里，它潜在地可能执行1600万条指令。**如果在传输进行时，只是简单地等待，什么也不做，这是一种极大的浪费**。

### 局部性

局部性可以理解为把一些内容缓存起来。

局部性通常有两种不同的形式：时间局部性和空间局部性。在一个具有良好**时间局部性**的程序中，被引用过一次的存储器位置很可能在不远的将来被多次引用。在一个具有良好**空间局部性**的程序中，如果一个存储器位置被引用了一次，那么程序很可能在不远的将来引用附近的一个存储器位置。

在硬件层，局部性原理允许计算机设计者通过引入称为高速缓存存储器的小而快速的存储器来保存最近被引用的指令和数据项，从而提高对主存的访问速度。在操作系统级，局部性原理允许系统使用主存作为虚拟地址空间最近被引用块的高速缓存。类似地，操作系统用主存来缓存磁盘文件系统中最近被使用的磁盘块。

Web浏览器将最近被引用的文档放在本地磁盘上，利用的就是时间局部性。大量的Web服务器将最近被请求的文档放在前端磁盘高速缓存中，这些缓存能满足对这些文档的请求，而不需要服务器的任何干预。

#### 一个说明局部性重要的例子

对于引用多维数组的程序来说，步长也是一个很重要的问题。一个对二维数组的元素求和。双重嵌套循环按照行优先顺序读数组元素。也就是说，内层循环读第一行的元素，然后读第二行......函数`sumarrayrows`具有良好的空间局部性，因为它按照数组被存储的行优先顺序来访问这个数组。其结果是得到一个很好的步长为1的引用模式和良好的空间局部性。

```c++
int sumarrayrows(int a[M][N]) {
	int i, j, sum = 0;

	for (i = 0; i < M; i++) {
		for (j = 0; j < N; j++) {
			sum += a[i][j];
		}
	}

	return sum;
}
```

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/26.PNG)

而一些看上去很小的对程序的改动能够对它的局部性有很大的影响。例如：

```c++
int sumarrayrows(int a[M][N]) {
	int i, j, sum = 0;

	for (j = 0; i < N; j++) {
		for (i = 0; i < M; i++) {
			sum += a[i][j];
		}
	}

	return sum;
}
```

这段代码和上面的区别就是它是按照列来遍历数组的。因为C数组在存储器中是按照行顺序来存放的，结果就是得到**步长为N**的引用模式。

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/27.PNG)

#### 取指令的局部性

因为程序指令是存放在存储器中的，CPU必须取出（读出）这些指令。**在`for`循环体里的指令是按照连续的存储器顺序执行的，因此循环有良好的空间局部性**。**因为循环体会被执行多次，所以它也有很好的时间局部性**。（循环体越小，循环迭代次数越多，局部性越好）

### 存储器层次结构示意图

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/28.PNG)

#### 存储器层次结构中的缓存

一般而言，高速缓存是一个小而快速的存储设备，它作为存储在更大、也更慢的设备中的数据对象的缓冲区域。**使用高速缓存的过程称为缓存**。

存储器层次结构的中心思想（**本质**）是，对于每个k，位于k层的更快更小的存储设备作为位于k + 1层的更大更慢的存储设备的缓存。换句话说，**每一层存储设备都是较低一层的缓存**。例如，本地磁盘作为通过网络从远程磁盘取出的文（例如Web页面）件的缓存，主存作为本地磁盘上数据的缓存，依此类推，直到最小的缓存--CPU寄存器集合。

下图中，第k + 1层的存储器被划分成连续的数据对象片，称为块。每个块都有一个唯一的地址或名字，使之区别于其他的块。块可以是固定大小的（通常是这样的），也可以是可变大小（如存储在Web服务器上的远程HTML文件）。例如下图的第k + 1层存储器被划分成16个大小固定的块，编号为0~15。

类似地，第k层的存储器被划分成较少的块的集合，每个块的大小与k + 1层的块的大小一样。在任何时刻，第k层的缓存包含第k+1层块的一个子集的拷贝。

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/29.PNG)

数据总是以块大小为传送单元在第k层和第k+1层之间来回拷贝的。虽然在层次结构中任何一对相邻的层次之间块大小是固定的，但是其他的层次对之间可以有不同的块大小。例如：L1和L0之间的传送通常使用的是1个字节的块；L2和L1之间的传送通常使用的是8~16个字节的块；而L5和L4之间的传送用的是大小为几百或几千字节的块。一般而言，层次结构中较低层（离CPU较远）的设备的访问时间较长，因此为了补偿这些较长的访问时间，倾向于使用较大的块。

### 缓存命中

**当程序需要第k+1层的某个数据对象d时，它首先在当前存储在第k层的一个块中查找d。如果d刚好缓存在第k层中，那么就是我们所说的缓存命中**。该程序直接从第k层读取d，根据存储器层次结构的性质，这要比从第k+1层读取d更快。

### 缓存不命中

**如果第k层中没有缓存数据对象d，那么就是我们所说的缓存不命中**。当发生缓存不命中时，**第k层的缓存从第k+1层缓存中取出包含d的那个块**，如果第k层的缓存已经满了的话，可能就会**覆盖**现存的一个块。

覆盖一个现存的块的过程称为**替换**这个块。决定替换哪个块是由缓存的替换策略来控制的。例如，一个具有随机替换策略的缓存会随机选择一个块。一个具有最近最少被使用（LRU）替换策略的缓存会选择那个最后被访问的时间距离现在最远的块。

在第k层缓存从第k+1层取出那个块之后，程序就能像前面一样从第k层读出d了。

### 缓存管理

在一个有虚拟存储器的系统中，**DRAM主存作为存储在磁盘上的数据块的缓存，是由操作系统软件和CPU上的地址翻译硬件共同管理的**。

### 编写高速缓存友好的代码

确保代码高速缓存友好的基本方法：

1、对局部变量的反复引用是好的，因为编译器能够将它们缓存在寄存器文件中（时间局部性）

2、步长为1的引用模式是最好的，因为存储器层次结构中所有层次上的缓存都是将数据存储为连续的块（空间局部性）。

## 7、链接

链接是将各种代码和数据部分收集起来并组合成一个单一文件的过程，这个文件可被加载（或被拷贝）到存储器并执行。链接可以执行于编译时，也就是在源代码被翻译成机器代码时；也可以执行于加载于，也就是在程序被加载器加载到存储器并执行时；甚至执行于运行时，有应用程序来执行。链接是由叫作链接器的程序自动执行的。

### 静态链接

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/30.PNG)

像Unix ld程序这样的静态链接器以一组可重定位目标文件和命令行参数作为输入，生成一个完全链接的可以加载和运行的可执行目标文件作为输出。输入的可重定位目标文件由各种不同的代码和数据节组成。指令在一个节中，初始化的全局变量在另一个节中，而为初始化的变量又在另一个节中。

**目标文件纯粹是字节块的集合**。这些块中，有些包含程序代码，有些则包含程序数据，而其他的则包含指导链接器和加载器的数据结构。**链接器将这些块连接起来，确定连接块的运行时位置，并且修改代码和数据块中的各种位置**。**链接器对目标机器了解甚少。产生目标文件的编译器和汇编器已经完成了大部分工作**。

### 可重定位目标文件

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/31.PNG)

```
.text: 已编译程序的机器代码
.rodata: 只读数据，比如printf语句中的格式串和开头语句的跳转表
.data: 已初始化的全局C变量。局部C变量在运行时保存在栈中，既不出现在.data节中，也不出现在.bss节中
.bss: 为初始化的全局C变量。在目标文件中这个节不占据实际的空间，它仅仅是一个占位符。目标文件格式区分初始化和未初始化变量是为了空间效率：在目标文件中，未初始化变量不需要占据任何实际的磁盘空间
.symtab: 一个符号表，是由汇编器构造的。符号表存放在程序中定义和引用的函数和全局变量的信息
```

认识到本地链接器符号和本地程序变量的不同是很重要的。**`.symtab`中的符号表不包含对应于本地非静态程序变量的任何符号**。这些符号在运行时**在栈中被管理**，**链接器对此类符号不感兴趣**。

有趣的是，定义为带有C static属性的本地过程（函数）变量是**不在栈中管理**的。相反，**编译器在`.data`和`.bss`中为每个定义分配空间，并在符号表中创建一个有唯一名字的本地链接器符号**。例如在同一个模块中的两个函数定义了一个静态本地变量x：

```c++
int f() {
	static int x = 0;
	return x;
}

int g() {
	static int x = 1;
	return x;
}
```

在这种情况中，编译器在`.data`中为两个整数分配空间，并引出（export）两个唯一的本地链接器符号给汇编。比如，它**可以用`x.1`表示函数`f`中的定义，而用`x.2`表示函数`g`中的定义**。

### 符号解析

链接器解析符号引用的方法是将每个引用与它输入的可重定位目标文件的符号表中的一个确定的符号定义联系起来。对那些和引用定义在相同模块中的本地符号的引用，符号解析是非常简单明了的。**编译器只允许每个模块中每个本地符号只有一个定义**。**编译器还确保静态本地变量，它们也会有本地链接器符号，拥有唯一的名字**。

不过，对全局符号的引用解析就棘手得多。当编译器遇到一个不是在当前模块中定义的符号（变量或函数名）时，它会假设该符号是在其他某个模块中定义的，生成一个链接器符号表条目，并把它交给链接器处理。如果链接器在它的任何输入模块中都找不到这个被引用的符号，它就输出一条错误信息并终止。例如，在一台Linux机器上编译和链接下面的源文件：

```c++
void foo(void);

int main(int argc, char const *argv[]) {
	foo();
	return 0;
}
```

那么**编译器会没有障碍地运行**，**但是当链接器无法解析对`foo`的引用时，它会终止**。

对全局变量的符号解析很棘手，还因为多个目标文件可能会定义相同的符号。在这种情况中，链接器必须要么标志一个错误，要么以某种方法选出一个定义并抛弃其他定义。

#### 对C++和Java中链接器符号的毁坏

C++和Java都允许重载，这些方法在源代码中有相同的名字，却有不同的参数列表。那么链接器是如何区别这些不同的重载函数之间的差异呢？C++和Java中能使用重载函数，是因为编译器将每个唯一的方法和参数列表组合编码成一个对链接器来说唯一的名字。这种编码过程叫做毁坏，而相反的过程叫做恢复。

C++和Java使用兼容的毁坏策略。一个被毁坏的类名字是由名字中字符的整数数量，后面跟原始名字组成的。比如，类Foo被编码成3Foo。方法被编码为原始方法名，后面加上`__`（两个下划线），加上被毁坏的类名，再加上每个参数的单个字母编码。比如，`Foo::bar(int, long)`被编码为`bar__3Fooil`。毁坏全局变量和模板名字的策略是相似的。

### 与静态库链接

所有的编译系统都提供一种机制，将所有相关的目标模块打包成为一个单独的文件，称为静态库，它可以用做链接器的输入。当链接器构造一个输出的可执行文件时，它只拷贝静态库里被应用程序引用的目标模块。

以ANSI C为例，它定义了一组广泛的标准I/O、字符串操作和整数数学函数，例如`atoi`、`printf`、`scanf`等等。

**相关的函数可以被编译为独立的目标模块，然后封装成一个单独的静态库文件。**然后，应用程序可以通过在命令行上指定单独的文件名字来使用这些在库中定义的函数。比如，使用标准C库和数序库中函数的程序可以用形式如下的命令行来编译和链接：

```shell
unix> gcc main.c /usr/lib/libm.a /usr/lib/libc.a
```

在链接时，链接器将只拷贝被程序引用的目标模块，这就减少了可执行文件在磁盘和存储器中的大小。另一方面，应用程序员只需要包含较少的库文件的名字。

### 加载可执行文件

要运行可执行目标文件p，可以在Unix外壳的命令行中输入它的名字：

```shell
unix> ./p
```

因为p不是一个内置的外壳命令，所以外壳会认为p是一个可执行目标文件，**通过调用某个驻留在存储器中称为加载器的操作系统代码来运行它**。加载器将可执行目标文件中的代码和数据从磁盘拷贝到存储器中。这个将程序拷贝到存储器并运行的过程叫做加载。

每个Unix程序都有一个运行时存储器映像，如图：

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/32.PNG)

在32位Linux系统中，代码段总是从地址`0x08048000`处开始。数据段是在接下来的下一个4KB对齐的地址处。运行时堆在读/写段之后接下来的第一个4KB对齐的地址处，并通过`malloc`库往上增长。还有一个段是为共享库保留的。用户栈总是从最大的合法用户地址开始，向下增长（向低存储器地址方向增长）。从栈的上部开始的段是为操作系统驻留存储器的部分（也就是内核）的代码和数据保留。

当加载器运行时，它会创建上图所示的存储器映像。加载器将可执行文件的相关内容拷贝到代码和数据段。接下来，加载器跳转到程序的入口点，也就是符号`_start`的地址。在`_start`地址处的启动代码是在目标文件`ctrl.o`中定义的，对所有的C程序都是一样的。启动代码调用`atexit`例程，这个程序附加了一系列在应用程序正常中止时应该调用的程序。`exit`函数运行`atexit`注册的函数，然后通过调用`_exit`将控制返回给操作系统。接着，**启动代码调用应用程序的`main`程序**，它会开始执行我们的C代码。在应用程序返回之后，启动代码调用`_exit`程序，它将控制返回给操作系统。

启动代码如下：

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/33.PNG)

#### 每个C程序都需要一个叫做main的函数的原因

C的启动代码对于每个C程序都是相同的，要跳转到一个叫做main的函数上。

一个可执行程序，也就是一个可执行的对象文件，它有一个程序进入点，这个进入点不是我们写的 main 函数，而是位于c 库中的 _start 汇编代码中。在这个汇编代码中，它会去调用我们写的 main C函数，而这个调用是写死的，所以我们没办法不用 main 函数。 实际上，假如你的C程序没用用 main 函数，那用 gcc 链接的时候，将会报错。

### 动态链接共享库

静态库和所有的软件一样，需要定期维护和更新。如果因为程序员想要使用一个库的最新版本，他们必须以某种方式了解到该库的最新情况，然后显式地将他们的程序与更新了的库重新链接。

**共享库是一个目标模块，在运行时，可以加载到任意的存储器地址，并和一个在存储器中的程序链接起来。这个过程称为动态链接**，是由一个叫做**动态链接器**的程序来执行的。**共享库的一个主要目的就是允许多个正在运行的进程共享存储器中相同的库代码，因而节约宝贵的存储器资源**。

共享库也称为共享目标，**在Unix系统中通常用`.so`后缀来表示**。在Windows操作系统中被称为DDL。

共享库是以两种不同的方式来“共享”的。首先，在任何给定的文件系统中，对于一个库只有一个`.so`文件。**所有引用该库的可执行目标文件共享这个`.so`文件中的代码和数据，而不是像静态库的内容那样拷贝和嵌入到引用它们的可执行的文件中**。其次，在存储器中，一个共享库的`.text`节的一个副本可以被不同的正在运行的进程共享。

应用程序还可能在它运行时要求动态链接器加载和链接任意共享库，而无需在编译时链接那些库到应用中。

#### 应用

##### 分发软件更新

只需要生成一个共享库的新版本，然后让用户下载，并用新版本替代当前的版本。下一次他们运行应用程序时，应用将自动链接和加载新的共享库。

##### 构建高性能Web服务器

许多Web服务器生成动态内容，。早期的Web服务器通过使用fork和execve创建一个子进程，并在该子进程的上下文中运行CGI程序来生成动态内容。然而，现代高性能的Web服务器可以使用基于动态链接的更有效和完善的方法来生成动态内容。

其思路是将生成动态内容的每个函数打包在共享库中。**当一个来自Web浏览器的请求到达时，服务器动态地加载和链接适当的函数，然后直接调用它，而不是使用fork和execve在子进程的上下文中运行函数**。函数会一直缓存在服务器的地址空间中，所以只要一个简单的函数调用的开销就可以处理随后的请求了。

## 8、异常控制流（ECF）

异常控制流发生在计算机系统的各个层次。比如，在硬件层，硬件检测到的事件会触发控制突然转移到异常处理程序。在操作系统层，内核通过上下文转换将控制从一个用户进程转移到另一个用户进程。在应用层，一个进程可以发送信号到另一个进程，而接收者会将控制突然转移到它的一个信号处理程序。

### 异常

异常是异常控制流的一种形式，它一部分是由硬件实现的，一部分是由操作系统实现的。

异常就是控制流中的突变，用来响应处理器状态中的某些变化。如下图：

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/34.PNG)

在图中，当处理器状态中发生一个重要的变化时，处理器正在执行某个当前指令Icurr。在处理器中，状态被编码为不同的位和信号。**状态变化称为事件**。**事件可能和当前指令的执行直接相关**。比如，发生虚拟存储器缺页、算术溢出，或者一条指令试图除以0.另一方面，**事件也可能和当前指令的执行没有关系**。比如，一个系统定时器产生信号或者一个I/O请求完成。

在任何情况下，当处理器检测到有事件发生时，它就会通过一张就做异常表的跳转表，进行一个间接过程调用（在跳转到处理程序之前，处理器将返回地址压入栈中。根据异常类型，返回地址要么是当前指令<当事件发生时正在执行的指令>，要么是下一条指令），到一个专门设计用来处理这类事件的操作系统子程序（异常处理程序）。

当异常处理程序完成处理后，根据引起异常的事件的类型，会发生一下三种情况中的一种：

1、处理程序将控制返回给当前指令Icurr，即当事件发生时正在执行的指令。

2、处理程序将控制返回给Inext，即如果没有发生异常将会执行的下一条指令。

3、处理程序终止被中断的程序。

### 异常处理

在系统启动时（当计算机重启或者加电时），操作系统分配和初始化一张称为异常表的跳转表，使得条目k包含异常k的处理程序的地址。如图：

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/35.PNG)

### 异常的类别

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/36.PNG)

#### 中断

中断是异步的，是来自处理器外部的I/O设备的信号的结果。

#### 陷阱

陷阱是同步的，是执行当前指令的结果。

陷阱是有意的异常，是执行一条指令的结果。就像中断处理程序一样，陷阱处理程序将控制返回到下一条指令。**陷阱最重要的用途是在用户程序和内核之间提供一个像过程一样的接口，叫做系统调用。**

用户程序经常需要向内核请求服务，比如读一个文件（read）、创建一个新的进程（fork）、加载一个新的程序（execve），或者终止当前进程（exit）。为了允许对这些内核服务的受控的访问，处理器提供了一条特殊的“syscall n”指令，当用户程序想要请求服务n时，可以执行这条指令。执行syscall指令会导致一个到异常处理程序的陷阱，并调用适当的内核程序。

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/37.PNG)

从程序员的角度来看，系统调用和普通的函数调用是一样的。然而，它们的实现是非常不同的。**普通的函数运行在用户模式中，用户模式限制了函数可以执行的指令的类型，而且它们只能访问与调用函数相同的栈**。**系统调用运行在内核模式中，内核模式允许系统调用执行指令，并访问定义在内核中的栈**。

#### 故障

故障是同步的，是执行当前指令的结果。

故障是由错误情况引起，它可能能够被故障处理程序修正。当故障发生时，处理器将控制转移给故障处理程序。如果处理程序能够修正这个错误情况，它就将控制返回到引起故障的指令，从而重新执行它。否则，处理程序返回到内核中的`abort`例程，`abort`例程会终止引起故障的应用程序。

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/38.PNG)

一个经典的故障示例是**缺页异常**，当指令引用一个虚拟地址，而该地址相对应的物理页面不在存储器中，因此必须从磁盘中取出时，就会发生故障。一个页面就是虚拟存储器的一个连续的块（典型是4KB）。缺页处理程序从磁盘加载适当的页面，然后将控制返回给引起故障的指令。当指令再次执行时，相应的物理页面已经驻留在存储器中了，指令就可以没有故障地运行完成了。

#### 终止

终止是同步的，是执行当前指令的结果。

终止是不可恢复的致命错误造成的结果，通常是一些硬件错误。**终止处理程序从不将控制返回给应用程序**。

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/39.PNG)

### 进程

异常是允许操作系统提供进程的概念所需要的基本构造块。

系统中的每个程序都是运行在某个进程上下文中的。上下文是由程序正确运行所需的状态组成的。这个状态包括存放在存储器中的程序的代码和数据，它的栈、通用目的寄存器的内容、程序计数器、环境变量以及打开的文件描述符的集合。

每次用户通过向外壳输入一个可执行目标文件的名字，并运行一个程序时，外壳就会创建一个新的进程，然后在这个新进程的上下文中运行这个可执行目标文件。

进程提供给应用程序的关键抽象：

1、一个**独立的逻辑控制流**，它提供一个假象，好像我们的程序独占地使用处理器。

2、一个**私有的地址空间**，它提供一个假象，好像我们的程序独占地使用存储器系统。

#### 逻辑流

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/40.PNG)

计算机系统中逻辑流有许多不同的形式。异常处理程序、进程、信号处理程序、线程和Java进程都是逻辑流的例子。

#### 并发流

**一个逻辑流的执行在时间上与另一个流重叠，称为并发流，这两个流被称为并发地运行。**更准确地说，流X和Y互相并发，当且仅当X在Y开始之后和Y结束之前开始，或者Y在X开始之后和X结束之前开始。在图8-12中，进程A和B并发运行，A和C也是。但是，B和C没有并发地运行，因为B的最后一条指令在C的第一条指令之前执行。

多个流并发地执行的一般现象称为并发。**一个进程和其他进程轮流运行的概念称为多任务。一个进程执行它的控制流的一部分的每一时间段叫做时间片。**

**注意：并发的思想与流运行的处理器核数或者计算机数无关。如果两个流在时间上重叠，那么它们就是并发的，即时它们是运行在同一个单核处理器上。**

并行流是并发流的真子集。如果两个流并发地运行在不同的处理器核或者计算机上，我们称它们为并行流，它们并行地运行，且并行地执行。

#### 私有地址空间

进程也为每个程序提供一种假象，好像它独占地使用系统地址空间。在一台与n位地址的机器上，地址空间是2的n次方个可能地址的集合，0， 1， ...，2的n次方 - 1。**一个进程为每个程序提供它自己的私有地址空间**。一般而言，**和这个空间中某个地址相关联的那个存储器字节是不能被其他进程读或者写的**，从这个意义上说，**这个空间是私有的**。

尽管和每个私有地址空间相关联的存储器的内容一般是不同的，但是每个这样的空间都有相同的通用结构。下图展示了一个x86Linux进程的地址空间的组织结构。

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/41.PNG)

地址空间底部是给用户程序用的，包括通常的文本、数据、堆和栈段。对于32位进程来说，代码段从地址0x08048000开始，对于64位进程来说，代码段从地址0x00400000开始。地址空间顶部是保留给内核的。地址空间的这个部分包含内核在代表进程执行指令时（比如，当应用程序执行一个系统调用时）使用的代码、数据和栈。

#### 用户模式和内核模式

为了使操作系统内核提供一个无懈可击的进程抽象，处理器必须提供一种机制，限制一个应用可以执行的指令以及它可以访问的地址空间范围。

处理器通常是用某个控制寄存器中的一个模式位来提供这种功能的。

**一个运行在内核模式的进程可以执行指令集中的任何指令，并且可以访问系统中任何存储器位置**。

**一个运行在用户模式的进程不允许执行特权指令，比如发起一个I/O操作、停止处理器等等**。也不允许用户模式中的进程直接引用地址空间中内核区内的代码和数据。反之，用户程序必须通过系统调用接口间接地访问内核代码和数据。

运行应用程序代码的进程初始时是在用户模式中的。**进程从用户模式变为内核模式的唯一方式是通过诸如中断、故障或者陷入系统调用这样的异常**。当异常发生时，控制传递到异常处理程序，处理器将模式从用户模式变为内核模式。**处理程序运行在内核模式中，当它返回应用程序代码时，处理器就把模式从内核模式改回到用户模式**。

#### 上下文切换

操作系统内核使用一种称为上下文切换的较高层形式的异常控制流来实现多任务。上下文切换机制是建立在那些较低层异常机制之上的。

内核为每个进程维持一个上下文。**上下文就是内核重新启动一个被抢占的进程所需的状态**。它由一些对象的值组成，这些对象包括通用目的寄存器、浮点寄存器、程序计数器、用户栈、内核栈、状态寄存器和各种数据结构，比如描绘地址空间的页表、包含有关当前进程信息的进程表，以及包含进程已打开文件的信息的文件表。

**在进程执行的某些时刻，内核可以决定抢占当前进程，并重新开始一个先前被抢占的进程**。这种决定就叫做调度，是由内核中称为调度器的代码处理的。在内核调度了一个新的进程运行后，它就抢占当前进程，并使用一种称为上下文切换的机制将控制转移到新的进程。

**当内核代表用户执行系统调用时，可能会发生上下文切换**。**如果系统调用因为等待某个事件发生而阻塞，那么内核可以让当前进程休眠，切换都另一个进程**。比如，**如果一个`read`系统调用请求一个磁盘访问，内核可以选择执行上下文切换，运行另外一个进程，而不是等待数据从磁盘到达**。另一个示例是`sleep`系统调用，它显示地请求让调用进程休眠。一般而言，即使系统调用没有阻塞，内核也可以决定执行上下文切换，而不是将控制返回给调用进程。

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/42.PNG)

磁盘取数据要用一段相对较长的时间（数量级为几十毫秒），所以内核执行从进程A到进程B的上下文切换，而不是在这个间歇时间内等待，什么都不做。注意在切换之前，内核正代表进程A在用户模式下执行指令。在切换的第一部分中，内核代表进程A在内核模式下执行指令。然后在某一时刻（中间的虚线位置），它开始代表进程B（仍然是内核模式下）执行指令。在切换之后，内核代表进程B在用户模式下执行指令。

随后，进程B在用户模式下运行一会儿，知道磁盘发出一个中断信号，表示数据已经从磁盘传送到了存储器。内核判定进程B已经运行了足够长的时间了，就执行一个从进程B到进程A的上下文切换，**将控制返回给进程A中紧随在系统调用`read`之后的那条指令**。进程A继续运行，直到下一次异常发生。

#### 创建和终止进程

新创建的子进程几乎但不完全与父进程相同。子进程得到与父进程用户级虚拟地址空间**相同的（但是独立的）一份拷贝**。独立的意思指的是：

```c++
#include "csapp.h"

int main(int argc, char const *argv[])
{
	pid_t = pid;
	int x = 1;

	pid = fork();

	if (pid == 0) {
		printf("child: x=%d\n", ++x);
		exit(0);
	}
    
    printf("parent:x=%d\n", --x);
    exit(0);

	return 0;
}
```

得到的结果可能是：

```shell
parent:x=0
chile:x=2
```

或者

```shell
chile:x=2
parent:x=0
```

如果能够**在fork函数在父进程和子进程中返回后立即暂停**这两个进程，我们会看到每个进程的地址空间都是相同的。每个进程有相同的用户栈、相同的本地变量值、相同的堆、相同的全局变量值，以及相同的代码。在示例中，当fork函数在第8行返回时，本地变量x在父进程和子进程中都为1。然而，因为父进程和子进程是独立的进程，它们都有自己的私有地址空间。父进程和子进程对x所做的任何改变都是独立的，不会反映在另一个进程的存储器中。这就是为什么当父进程和子进程调用它们各自的printf语句时，它们中的变量x会有不同的值的原因。

父进程和子进程共享文件。我们注意到，在可能的第一种结果里面，父进程和子进程都把它们的输出显示在屏幕上。原因是子进程继承了父进程所有的打开文件。**当父进程调用fork时，stdout文件是被打开的，并指向屏幕。子进程继承了这个文件，因此它的输出也是指向屏幕的。**

#### fork程序和它们的进程图

```c++
#include "csapp.h"

int main(int argc, char const *argv[])
{
	fork();
	fork();
	fork();
	printf("hello\n");
	exit(0);
}
```

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/43.PNG)

其中每个水平的箭头对应于从左到右执行指令的进程，而每个垂直的箭头对应于fork函数的执行。所以，执行的总的次数（也就是总的进程数）是2的n次方（其中n是fork函数的个数）。

#### 回收子进程

当一个进程由于某种原因终止时，内核并不是立即把它从系统中清除。相反，进程被保持在一种已终止的状态中，直到被它的父进程回收。当父进程回收已终止的子进程时，内核将子进程的退出状态传递给父进程，然后抛弃已终止的进程，从此时开始，该进程就不存在了。一个终止了但还未被回收的进程称为**僵死进程**。

**如果父进程没有回收它的僵死子进程就终止了，那么内核就会安排init进程来回收它们**。init进程的PID为1，并且是在系统初始化时**由内核创建**的。**即使僵死子进程没有运行，它们仍然消耗系统的存储器资源**。

#### 加载并运行程序

execve函数在当前进程的上下文中加载并运行一个新程序。execve函数在当前进程的上下文中加载并运行一个新的程序。它会**覆盖当前进程的地址空间**，但并没有创建一个新进程。新的程序仍然有相同的PID，并且继承了调用execve函数时已打开的所有文件描述符。

## 9、虚拟存储器

具有请求调入功能和置换功能，能从逻辑上对内存容量加以扩充的一种存储系统。

即，**程序在运行之前，没必要全部装入内存，仅把当前要运行的页装入即可，当程序运行时，如果需要其它页面，再进行页面调入或者置换**。

这样，假如内存为1G，硬盘为200G，每个程序的大小为2G。

那么该os可以同时装100个程序进内存（甚至可以更多，此处是100，是因为硬盘大小的限制）。而此前的os一个程序也装不下。

也就是说，在用户看来，内存的容量变为了200G，因为有100个2G的程序被装入内存了。

但实际的内存只有1G，因此将这种存储系统称为虚拟存储器。

虚拟存储器提供了三个主要的能力：

1、它将主存看成是一个存储在磁盘上的地址空间的高速缓存，在主存中只保存活动区域，并根据需要在磁盘和主存之间来回传送数据，通过这种方式，它高效地使用了主存。

2、它为每个进程提供了一致的地址空间，从而简化了存储器管理。

3、**它保护了每个进程的地址空间不被其他进程破坏**。

虚拟存储器给予应用程序强大的能力，可以创建和销毁存储器片、将存储器片映射到磁盘文件的某个部分，以及与其他进程共享存储器。比如，**可以通过读写存储器位置读或者修改一个磁盘文件的内容；可以加载一个文件的内容到存储器中，而不需要任何显示的拷贝**。

### 物理寻址和虚拟寻址

CPU直接访问存储器的方式就是物理寻址。

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/44.PNG)

而使用虚拟寻址时，CPU通过生成一个虚拟地址来访问内存，这个虚拟地址在被送到存储器之前先转换成适当的物理地址。

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/45.PNG)

将一个虚拟地址转换为物理地址的任务叫做地址翻译。地址翻译需要CPU硬件和操作系统之间的紧密合作。

### 地址空间

地址空间是一个非负整数地址的有序集合：

```
{0, 1, 2, ...}
```

地址空间的概念是很重要的，因为它清楚地区分了数据对象（字节）和它们的属性（地址）。一旦认识到了这种区别，那么我们就可以将其推广，允许每个数据对象有多个独立的地址，其中每个地址都选自一个不同的地址空间。这就是虚拟存储器的基本思想。**主存中的每个字节都有一个选自虚拟地址空间的虚拟地址和一个选自物理地址空间的物理地址**。

### 虚拟存储器作为缓存工具

虚拟存储器（VM）被组织为一个由**存放在磁盘上**的N个连续的字节大小的单元组成的数组。**每个字节都有一个唯一的虚拟地址**，这个唯一的虚拟地址是作为到数组的索引的。**磁盘上数组的内容被缓存在主存中**。和存储器层次结构中其他缓存一样，磁盘（较低层）上的数据被分割成块，这些块作为磁盘和主存（较高层）之间的传输单元。VM系统通过将虚拟存储器分割为称为虚拟页的大小固定的块来处理这个问题。每个虚拟页的大小为P=2的p次方字节。类似地，物理存储器被分割为物理页，大小也为P字节。

#### 虚拟页面的集合分为三个不相交的子集

##### 未分配的

虚拟存储器还未分配（或者创建）的页。未分配的块没有任何数据和它们相关联，因此也就不占用任何磁盘空间。

##### 缓存的

当前缓存在物理存储器中的已分配页。

##### 未缓存的

没有缓存在物理存储器中的已分配页。

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/46.PNG)

虚拟页面0和3还没有被分配，因此在磁盘上还不存在。

#### 页表

同任何缓存一样，虚拟存储器系统必须有某种方法来判定一个虚拟页是否存放在DRAM中的某个地方。如果是，系统还必须确定这个虚拟页存放在哪个物理页中。如果不命中，系统必须判断这个虚拟页存放在磁盘的哪个位置，在物理存储器中选择一个牺牲页，并将虚拟页从磁盘拷贝到DRAM中，替换这个牺牲页。

这些功能是由许多软硬件联合提供的，包括操作系统软件、MMU（存储器管理单元）中的地址翻译硬件和一个**存放在物理存储器中叫做页表的数据结构，页表将虚拟页映射到物理页。每次地址翻译硬件将一个虚拟地址转换为物理地址时都会读取页表**。操作系统负责维护页表的内容，以及在磁盘与DRAM之间来回传送页。

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/47.PNG)

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/48.PNG)

如果设置了有效位，说明DRAM中的物理页缓存了该虚拟页。

#### 缺页

DRAM缓存不命中称为缺页。

缺页异常调用内核中的缺页异常处理程序，该程序会选择一个牺牲页。

在虚拟存储器的习惯说法中，**块被称为页**。在磁盘和存储器之间传送页的活动叫做**交换或者页面调度**。页从磁盘换入（或者页面调入）DRAM和从DRAM换出（或者页面调出）磁盘。一直等待，直到最后时刻，也就是当有不命中发生时，才换入页面的这种策略称为**按需页面调度**。

#### 分配页面

当操作系统分配一个新的虚拟存储器页时对页表的影响（例如，调用malloc的结果）。在这个示例中，通过在磁盘上创建空间并更新PTE5，使它指向磁盘上这个新创建的页面，从而分配VP5。（此时还没有缓存在主存里面）

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/49.PNG)

#### 虚拟存储器作为存储器管理的工具

操作系统**为每个进程提供了一个独立的页表**，因而**也就是一个独立的虚拟地址空间**。如图：

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/50.PNG)

##### 简化加载

虚拟存储器使得容易向存储器中加载可执行文件和共享对象文件。加载器从不实际拷贝任何数据从磁盘到存储器。在每个页初次被引用时，要么是CPU取指令时引用，要么是一条正在执行的指令引用一个存储器位置时引用的，虚拟存储器系统会按照需要自动地调入数据页。

将一组连续的虚拟页映射到任意一个文件中的任意位置的表示法称作存储器映射。

##### 简化共享

独立地址空间为操作系统提供了一个管理用户进程和操作系统自身之间共享的一致机制。一般而言，每个进程都有自己私有的代码、数据、堆以及栈区域，是不和其他进程共享的。在这种情况下，**操作系统创建页表，将相应的虚拟页映射到不同的物理页面**。

然而，在一些情况下，还是需要进程来共享代码和数据。例如，每个进程必须调用相同的操作系统内核代码，而每个C程序都会调用C标准库中的程序，如`printf`。操作系统通过将不同**进程中适当的虚拟页面**映射到相同的物理页面，从而安排多个进程共享这部分代码的一个拷贝，而不是在每个进程中都包括单独的内核和C标准库的拷贝。

##### 简化存储器分配

虚拟存储器为向用户进程提供一个简单的分配额外存储器的机制。第一个运行在用户进程中的程序要求额外的堆空间时（如调用malloc的结果），操作系统分配一个适当数字（例如k）个连续的虚拟存储器页面，并且将它们映射到物理存储器中任意位置的k个任意的物理页面。由于页表工作的方式，**操作系统没有必要分配k个连续的物理存储器页面。页面可以随机地分散在物理存储器中**。

#### 虚拟存储器作为存储器保护的工具

通过虚拟存储器来控制对某块地址的读写权限。

### 存储器映射

Linux通过将一个虚拟存储器区域与一个磁盘上的对象关联起来，以初始化这个虚拟存储器区域的内容，这个过程称为存储器映射。

虚拟存储器区域可以映射到两种类型的对象中的一种：

**Unix文件系统中的普通文件**：将一个普通文件的全部或者一部分映射到进程的虚拟内存中。映射后，进程就可以直接在对应的内存区域操作文件内容。一个区域可以映射到一个普通磁盘文件的连续部分，例如一个可执行目标文件。文件区被分成页大小的片。因为按需进行页面调度，所以这些虚拟页面没有实际交换进入物理存储器，直到CPU第一次引用页面。

**匿名文件**：一个区域也可以映射到一个匿名文件，匿名文件是由内核创建的，包含的全是二进制零。CPU第一次引用这样一个区域内的虚拟页面时，内核就在物理存储器中找到一个合适的牺牲页，如果该页面被修改过，就将这个页面换出来，用二进制零覆盖牺牲页面并更新页表，将这个页面标记为是驻留在存储器中的。注意，在磁盘和存储器之间并没有实际的数据传送。

#### 共享对象

许多程序需要访问只读运行时库代码的相同拷贝。例如，每个C程序都可能需要来自标准C库的诸如`printf`这样的函数。那么，如果每个进程都在物理存储器中保持这些常用代码的复制拷贝，那就是极端的浪费了。幸运的是，**存储器映射给我们提供了一种清晰的机制，用来控制多个进程如何共享对象**。

一个对象可以被映射到虚拟存储器的一个区域，要么作为**共享对象**，要么作为**私有对象**。如果一个进程将一个共享对象映射到它的虚拟地址空间的一个区域内，那么**这个进程对这个区域的任何写操作，对于那些也把这个共享对象映射到它们虚拟存储器的其他进程而言也是可见的。而且，这些变化也会反映在磁盘上的原始对象中。**

另一方面，**对一个映射到私有对象的区域做的改变，对于其他进程来说是不可见的，并且进程对这个区域所做的任何写操作都不会反映在磁盘上的对象中**。**一个映射到共享对象的虚拟存储器区域叫做共享区域**。类似地，也有**私有区域**。

假设进程1将一个共享对象映射到它的虚拟存储器的一个区域中，如图：

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/51.PNG)

现在假设进程2将同一共享对象映射到它的地址空间（并不一定要和进程1在相同的虚拟地址处），如图：

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/52.PNG)

因为每个对象都有一个唯一的文件名，内核可以迅速地判断进程1已经映射了这个对象，而且可以使进程2中的页表条目指向相应的物理页面。关键点在于即使对象被映射到了多个共享区域，物理存储器中也只需要存放共享对象的一个拷贝。

私有对象是使用一种叫做写时拷贝的巧妙技术被映射到虚拟存储器中的。一个私有对象开始生命周期的方式基本上与共享对象的一样，在物理存储器中只保存有私有对象的一份拷贝。如图：

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/53.PNG)

其中两个进程将一个私有对象映射到它们虚拟存储器的不同区域，但是**共享这个对象同一个物理拷贝**。对于每个映射私有对象的进程，相应私有区域的页表条目都被标记为只读，并且区域结构被标记为**私有的写时拷贝**。只要没有进程试图写它自己的私有区域，它们就可以继续共享物理存储器中对象的一个单独拷贝。然而，**只要有一个进程试图写私有区域内的某个页面，那么这个写操作就会触发一个保护故障**。

当故障处理程序注意到保护异常是由于进程试图写私有的写时拷贝区域中的一个页面而引起的，它就会在物理存储器中创建这个页面的一个新拷贝，更新页表条目指向这个新的拷贝，然后恢复这个页面的可写权限。如图：

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/54.PNG)

#### fork函数

当fork函数被当前进程调用时，内核为新进程创建各种数据结构，并分配给它一个唯一的PID。为了给这个新进程创建虚拟存储器，它创建了当前进程的`mm_struct`、区域结构和页表的原样拷贝。它将两个进程中的每个页面都标记为只读，并将两个进程中的每个区域结构都标记为私有的写时拷贝。

当fork在新进程中返回时，新进程现在的虚拟存储器刚好和调用fork时存在的虚拟存储器相同。**当两个进程中的任一个后来进行写操作时，写时拷贝机制就会创建新页面，因此，也就为每个进程保持了私有地址空间的抽象概念**。

### 动态存储器分配

动态存储器分配器维护着一个进程的虚拟存储器区域，称为堆。

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/55.PNG)

除了`new`、`malloc`等等，还可以使用`mmap`和`munmap`函数，显示地分配和释放堆存储器。

#### 为什么要使用动态存储器分配

经常直到程序实际运行时，它们才知道某些数据结构的大小。

## 10、系统级I/O

输入/输出（I/O）是在主存和外部设备（如磁盘驱动器、终端和网络）之间拷贝数据的过程。**输入操作是从I/O设备拷贝数据到主存（读操作），而输出操作是从主存拷贝数据到I/O设备（写操作）**。

### 读和写文件

在某些情况下，read和write传送的字节比应用程序要求的要少。这些不足值不表示有错误。实际上，除了EOF，在读磁盘文件时，将不会遇到不足值，而且在写磁盘文件时，也不会遇到不足值。然而，如果想要创建健壮的（可靠的）诸如Web服务器这样的网络应用，就必须通过反复调用`read`和`write`处理不足值，直到所有需要的字节都传送完毕。

### 无缓冲的输入输出函数

这些函数**直接在存储器和文件之间传送数据，没有应用级缓冲**。它们对将二进制数据读写到网络和从网络读写二进制数据尤其有用。

### 带缓冲的输入函数

这些函数允许你高效地从文件中读取文本行和二进制数据，这些文件的内容缓存在应用级缓冲区内，类似于为像`printf`这样的标准I/O函数提供的缓冲区。

### I/O重定向

Unix外壳提供了I/O重定向操作符，允许用户将磁盘文件和标准输入输出联系起来。例如，键入：

```shell
unix> ls > foo.txt
```

使得外壳加载和执行`ls`程序。

## 12、并发编程

如果逻辑控制流在时间上是重叠的，那么它们就是并发的。这种常见的现象称为并发。

当一个应用正在等待来自慢速I/O设备（例如磁盘）的数据到达时，内核会运行其他进程，是CPU保持繁忙。每个应用都可以按照类似的方式，通过交替执行I/O请求和其他有用的工作来使用并发。

迭代网络服务器是不现实的，因为它们一次只能为一个客户端提供服务。因此，一个慢速的客户端可能会导致服务器拒绝为所有其他客户端服务。对于一个真正的服务器来说，可能期望它每秒为成百上千的客户端提供服务，由于一个慢速客户端导致拒绝为其他客户端服务，这是不能接受的。一个更好的方法是创建一个并发服务器，它**为每个客户端创建一个单独的逻辑流**。这就允许服务器同时为多个客户端服务，并且这也避免了慢速客户端独占服务器。

在多核机器上进行并行计算。许多现代系统都配备有多核处理器，多核处理器中包含多个CPU。被划分成并发流的应用程序通常在多核机器上比在单核处理器机器上运行得快，因为这些流会并行执行，而不是交错执行。

**线程是运行在一个单一进程上下文中的逻辑流，由内核进行调度**。

### 基于进程的并发编程

构造并发程序最简单的方法就是用进程。例如，一个构造并发服务器的自然方法就是，**在父进程中接受客户端连接请求，然后创建一个新的子进程来为每个新客户端提供服务**。

#### 关于进程的优劣

对于父、子进程间共享状态信息，进程有一个非常清晰的模型：共享文件表，但是不共享用户地址空间。进程有独立的地址空间既是优点也是缺点。这样一来，一个进程不可能不小心覆盖另一个进程的虚拟存储器。另一方面，独立的地址空间使得进程共享状态信息变得更加困难。为了共享信息，它们必须使用显式的IPC（进程间通信）机制。基于进程的设计的另一个缺点是，它们往往比较慢，因为进程控制和IPC的开销很高。

### 基于线程的并发编程

第一种创建并发逻辑流的方法是为每个流使用了单独的进程，那么每个进程有它自己的私有地址空间，这使得流共享数据很困难。

第二种方法是创建自己的逻辑流，并利用I/O多路复用来显式地调用流。因为只有一个进程，所有的流共享整个地址空间。

而基于线程的方法创建并发逻辑流是上面两种方法的混合。

线程就是运行在进程上下文中的逻辑流。**线程由内核自动调度**。每个线程都有它自己的线程上下文。所有运行在一个进程里的线程共享该进程的整个虚拟地址空间。

基于线程的逻辑流结合了基于进程和基于I/O多路复用的流的特性。同进程一样，线程由内核自动调度，并且内核通过一个整数ID来识别线程。同基于I/O多路复用的流一样，多个线程运行在单一进程的上下文中，因此共享这个进程虚拟地址空间的整个内容，包括它的代码、数据、堆、共享库和打开的文件。

每个进程开始生命周期时都是单一线程，这个线程称为主线程。在某一时刻，主线程创建一个对等线程，从这个时间点开始，两个线程就并发地运行。

![](http://oklbfi1yj.bkt.clouddn.com/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/56.PNG)

线程执行是不同于进程的。因为一个线程的上下文要比一个进程的上下文小得多，线程的上下文切换要比进程的上下文切换快得多。另一个不同就是线程不想进程那样，不是按照严格的父子层次来组织的。和一个进程相关的线程组成一个对等（线程）池，独立于其他线程创建的线程。主线程和其他线程的区别仅在于它总是进程中第一个运行的线程。对等（线程）池概念的主要影响是，一个线程可以杀死它的任何对等线程，或者等待它的任意对等线程终止。另外，每个对等线程都能读写相同的共享数据。






























































































































































































































































































































































































